{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 13:19:18.225640: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "CEVAE moargs.latent_dimensionel on IHargs.latent_dimensionP\n",
    "\"\"\"\n",
    "##################### Neeargs.latent_dimension TF1\n",
    "# import edward as ed\n",
    "# import tensorflow as tf\n",
    "# from utils import fc_net, get_y0_y1\n",
    "# from edward.models import Bernoulli, Normal\n",
    "# from progressbar import ETA, Bar, Percentage, ProgressBar\n",
    "###############################################################\n",
    "import os\n",
    "# import json\n",
    "# import time\n",
    "# import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy.stats import sem\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.keras.layers as tfkl\n",
    "tfd,tfpl = tfp.distributions,tfp.layers\n",
    "import tensorflow.keras.backend as tfkb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import IHDP\n",
    "from evaluation import Evaluator\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "################### CEVAE\n",
    "parser.add_argument('-reps', type=int, default=10)\n",
    "parser.add_argument('-earl', type=int, default=10)\n",
    "parser.add_argument('-lr', type=float, default=0.001)\n",
    "parser.add_argument('-decay', type=float, default=0.001)\n",
    "parser.add_argument('-opt', choices=['adam', 'adamax'], default='adam')\n",
    "parser.add_argument('-epochs', type=int, default=100)     \n",
    "parser.add_argument('-print_every', type=int, default=10)\n",
    "################### BASIC\n",
    "parser.add_argument('--num_parallel_reads', type = int, default = 10, help = 'random seed')\n",
    "parser.add_argument('--random_seed', type = int,default = 9418, help = 'random seed')\n",
    "parser.add_argument('--mode', type = str, default = 'train', help = 'train or evaluate')\n",
    "args = parser.parse_args([])\n",
    "args.true_post = True\n",
    "#################################From CEVAE\n",
    "dataset = IHDP(replications=args.reps)\n",
    "dimx = 25\n",
    "scores = np.zeros((args.reps, 3))\n",
    "scores_test = np.zeros((args.reps, 3))\n",
    "#################################IHDP Data\n",
    "# data information \n",
    "t_bin_dim = 1\n",
    "y_dim, default_y_scale = 1,tf.exp(0.)\n",
    "M = None        # batch size during training\n",
    "z_dim = 20          # latent z dimension\n",
    "lamba = 1e-4    # weight decay\n",
    "nh, h = 3, 200  # number and size of hidden layers\n",
    "binfeats = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
    "numfeats = [i for i in range(25) if i not in binfeats]\n",
    "x_bin_dim = len(binfeats)\n",
    "x_num_dim = len(numfeats)\n",
    "################################# some functions needed\n",
    "def findfile(start, name):\n",
    "    ans = []\n",
    "    for relpath, dirs, files in os.walk(start):\n",
    "        for file in files:\n",
    "            if name in file:\n",
    "                full_path = os.path.join(start, file)\n",
    "                ans.append(full_path)\n",
    "                # print(os.path.normpath(os.path.abspath(full_path)))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create datasets\n",
    "# data_all = []\n",
    "# for data in findfile(\"./datasets/IHDP/csv\",'.csv'):\n",
    "#     try:\n",
    "#         data_all = data_all.append(pd.read_csv(data, header = None), ignore_index = True)\n",
    "#     except:\n",
    "#         data_all = pd.read_csv(data, header = None)\n",
    "# data_all.columns = ['treatment', 'y_factual', 'y_cfactual', 'mu0', 'mu1', ] + ['x'+str(i) for i in range(25)]\n",
    "# y_mean,y_std = np.mean(data_all['y_factual']),np.std(data_all['y_factual'])\n",
    "# data_all['y_factual'] = (data_all['y_factual'] - y_mean) / y_std\n",
    "# data_all['x13'] = data_all['x13'] - 1\n",
    "# # set random seeds:\n",
    "# np.random.seed(7)\n",
    "# data_train, data_valid = train_test_split(data_all, test_size=0.2, )\n",
    "# data_train.to_csv(\"./datasets/IHDP/csv_create/train.csv\", header = None, index =None)\n",
    "# data_valid.to_csv(\"./datasets/IHDP/csv_create/valid.csv\", header = None, index =None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ihdp_fn(data):\n",
    "    data = tf.strings.to_number(tf.strings.split(data, sep=','))\n",
    "    t, y, y_cf = data[0:1], data[1:2], data[2:3]\n",
    "    mu_0, mu_1, x = data[3:4], data[4:5], data[5:]\n",
    "    x_bin = x[..., x_num_dim:]  # binary inputs\n",
    "    x_num = x[..., 0:x_num_dim]  # continuous inputs\n",
    "    return [x_bin, x_num, t, y, y_cf, mu_0, mu_1]\n",
    "    \n",
    "def input_fn_csv(path,name, batch_size=128, shuffle_size=0):\n",
    "    all_files = findfile(path,name)\n",
    "    ds = tf.data.TextLineDataset(\n",
    "        all_files,\n",
    "        compression_type= None,\n",
    "        num_parallel_reads=int(args.num_parallel_reads),\n",
    "        buffer_size=64*1024*1024# 可选参数，多线程并行读多个文件\n",
    "    ).repeat(args.reps)\n",
    "    if shuffle_size > 0:\n",
    "        ds = ds.shuffle(shuffle_size)\n",
    "    ds = ds.map(ihdp_fn).batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import p_x_z, p_t_z, p_y_tz, q_t_x, q_y_xt, q_z_xyt\n",
    "class CEVAE(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CEVAE, self).__init__()\n",
    "        ########################################\n",
    "        # networks\n",
    "        self.activation = 'elu'\n",
    "        # CEVAE Model (decoder)\n",
    "        # p(z)\n",
    "        self.z = tfd.Normal(loc = [0]*z_dim, scale = [1]*z_dim)\n",
    "        # p(x|z)\n",
    "        self.p_x_z = p_x_z(x_bin_dim, x_num_dim, z_dim, nh, h)\n",
    "        # p(t|z)\n",
    "        self.p_t_z = p_t_z(t_bin_dim, z_dim,h)\n",
    "        # p(y|t,z)\n",
    "        self.p_y_tz = p_y_tz(y_dim, t_bin_dim, z_dim,default_y_scale, nh, h )\n",
    "        # CEVAE Model (encoder)\n",
    "        # q(t|x)\n",
    "        self.q_t_x = q_t_x(x_bin_dim, x_num_dim, t_bin_dim, z_dim, nh, h)\n",
    "        # q(y|x,t)\n",
    "        self.q_y_xt = q_y_xt(x_bin_dim, x_num_dim, y_dim, t_bin_dim, default_y_scale, nh, h)\n",
    "        # q(z|x,t,y)\n",
    "        self.q_z_xyt = q_z_xyt(x_bin_dim, x_num_dim, y_dim, t_bin_dim, z_dim, nh, h) \n",
    "        ########################################\n",
    "        # optimizers\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            args.lr,\n",
    "            decay_steps=1,\n",
    "            decay_rate=args.decay,\n",
    "            staircase=True)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule)\n",
    "\n",
    "    def call(self, data, training=False, serving=False):\n",
    "        # Dataset_inp\n",
    "        # input data preprocess\n",
    "        [x_ph_bin, x_ph_num, t, y, _, _, _] = data\n",
    "        x_ph = tf.concat([x_ph_bin, x_ph_num], -1)\n",
    "        # CEVAE variational approximation (encoder)\n",
    "        ## q(t|x)\n",
    "        qt = self.q_t_x(x_ph)\n",
    "        ## q(y|x,t)\n",
    "        xt_inputs = tf.concat([x_ph,qt],-1)\n",
    "        qy = self.q_y_xt(xt_inputs)\n",
    "        ## q(z|x,t,y)\n",
    "        xyt_input = tf.concat([x_ph, qy, qt], axis=-1)\n",
    "        qz = self.q_z_xyt(xyt_input)\n",
    "\n",
    "        # CEVAE model (decoder)\n",
    "        ## p(x|z)\n",
    "        [x_infer_bin,x_infer_num] = self.p_x_z(qz)\n",
    "        ## p(t|z)\n",
    "        t_infer = self.p_t_z(qz)\n",
    "        ## p(y|t,z)\n",
    "        y_infer = self.p_y_tz(tf.concat([t_infer,qz],-1))\n",
    "        \n",
    "        output = [x_infer_bin,x_infer_num,t_infer,y_infer, qz,qt,qy,]\n",
    "        return output\n",
    "\n",
    "    def cevae_loss(self,data,pred):\n",
    "        # get preds\n",
    "        [x_bin,x_num,t,y,qz,qt,qy] = pred\n",
    "        # read labels\n",
    "        [x_bin_real,x_num_real, t_real, y_real, y_cf_real, mu_0_real, mu_1_real] = data\n",
    "        # Reconstruction loss\n",
    "        ## p(x|z)\n",
    "        loss = {}\n",
    "        loss['loss_p_x_z_bin'] = tfkb.mean(x_bin.log_prob(x_bin_real))\n",
    "        loss['loss_p_x_z_num'] = tfkb.mean(x_num.log_prob(x_num_real))\n",
    "        ## p(t|z)\n",
    "        loss['loss_p_t_z_bin'] = tfkb.mean(t.log_prob(t_real))\n",
    "        ## p(y|t,z)\n",
    "        loss['loss_p_y_tz'] = tfkb.mean(y.log_prob(y_real))\n",
    "        # REGULARIZATION LOSS\n",
    "        ## p(z) - q(z|x,t,y)\n",
    "        ## approximate KL\n",
    "        ### calculate based on sample returns none value\n",
    "        # reg_loss_q_z = tfkb.mean(self.z.log_prob(qz.sample()) - qz.log_prob(qz.sample()))\n",
    "        ### try use Analytic KL (seems to make overall performance less stable)\n",
    "        # reg_loss_q_z = tfkb.mean(-tf.math.log(qz.stddev) + 1/2*(qz.variance + qz.mean**2 - 1))\n",
    "        # tf.print(reg_loss_q_z)\n",
    "        # AUXILIARY LOSS\n",
    "        ## q(t|x)\n",
    "        loss['aux_loss_q_t_x'] = tfkb.mean(qt.log_prob(t_real))\n",
    "        ## q(y|x,t)\n",
    "        loss['aux_loss_q_y_xt'] = tfkb.mean(qy.log_prob(y_real))\n",
    "        \n",
    "        loss_all = loss['loss_p_x_z_bin'] + loss['loss_p_x_z_num'] + loss['loss_p_t_z_bin'] + loss['loss_p_y_tz'] + loss['aux_loss_q_t_x'] + loss['aux_loss_q_y_xt']\n",
    "        \n",
    "        # tf.print(loss)\n",
    "        return -loss_all\n",
    "\n",
    "    def get_y0_y1(self, x_train, t_train, L=1):\n",
    "        y_infer = self.q_y_xt(tf.concat([x_train, t_train],-1))\n",
    "        # use inferred y\n",
    "        xyt = tf.concat([x_train, y_infer, t_train], -1)  # TODO take mean?\n",
    "        z_infer = self.q_z_xyt(xyt)\n",
    "        # Manually input zeros and ones\n",
    "        y0 = self.p_y_tz(tf.concat([t_train,tf.zeros_like(z_infer)],-1)).mean()  # TODO take mean?\n",
    "        y1 = self.p_y_tz(tf.concat([t_train,tf.ones_like(z_infer)],-1)).mean()  # TODO take mean?\n",
    "        return y0,y1\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = self(data, training=True)  # Forward pass\n",
    "            # Compute the loss value.\n",
    "            # The loss function is configured in `compile()`.\n",
    "            loss = self.cevae_loss(data,pred)\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.optimizer.lr.assign(args.lr)\n",
    "        ##########################################################\n",
    "        #  metrics\n",
    "        [x_bin_real,x_num_real, t_real, y_real, y_cf, mu0, mu1] = data\n",
    "        evaluate_metric = Evaluator(y = y_real, t = t_real, y_cf=y_cf, mu0=mu0, mu1=mu1)\n",
    "        metrics = {\"loss\":loss, }\n",
    "        # Compute our own metrics\n",
    "        x_real = tf.concat([x_bin_real,x_num_real],-1)\n",
    "        y0, y1 = self.get_y0_y1(x_real,t_real)\n",
    "        score_train = evaluate_metric.calc_stats(y1, y0)\n",
    "        rmses_train = evaluate_metric.y_errors(y0, y1)\n",
    "        metrics.update({\n",
    "            \"train ite\": score_train[0], \n",
    "            \"train ate\": score_train[1],\n",
    "            \"train pehe\": score_train[2], \n",
    "            \"train rmse\":rmses_train[0],\n",
    "            \"train rmse counterfactual\":rmses_train[1],\n",
    "            })\n",
    "        return metrics\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        ##########################################################\n",
    "        #  metrics\n",
    "        [x_bin_real,x_num_real, t_real, y_real, y_cf, mu0, mu1] = data\n",
    "        evaluate_metric = Evaluator(y = y_real, t = t_real, y_cf=y_cf, mu0=mu0, mu1=mu1)\n",
    "        metrics = {}\n",
    "        # Compute our own metrics\n",
    "        x_real = tf.concat([x_bin_real,x_num_real],-1)\n",
    "        y0, y1 = self.get_y0_y1(x_real,t_real)\n",
    "        score_train = evaluate_metric.calc_stats(y1, y0)\n",
    "        rmses_train = evaluate_metric.y_errors(y0, y1)\n",
    "        metrics.update({\n",
    "            \"valid ite\": score_train[0], \n",
    "            \"valid ate\": score_train[1],\n",
    "            \"valid pehe\": score_train[2], \n",
    "            \"valid rmse\":rmses_train[0],\n",
    "            \"valid rmse counterfactual\":rmses_train[1],\n",
    "            })\n",
    "        return metrics\n",
    "\n",
    "def build_model():\n",
    "    model = CEVAE()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(args.lr))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 13:19:18.524804: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_12/kernel:0', 'dense_12/bias:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'dense_14/kernel:0', 'dense_14/bias:0', 'dense_15/kernel:0', 'dense_15/bias:0', 'Variable:0', 'dense_28/kernel:0', 'dense_28/bias:0', 'dense_29/kernel:0', 'dense_29/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_12/kernel:0', 'dense_12/bias:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'dense_14/kernel:0', 'dense_14/bias:0', 'dense_15/kernel:0', 'dense_15/bias:0', 'Variable:0', 'dense_28/kernel:0', 'dense_28/bias:0', 'dense_29/kernel:0', 'dense_29/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "467/467 [==============================] - 12s 18ms/step - loss: 2.4557 - train ite: 9.8693 - train ate: 4.7819 - train pehe: 10.1258 - train rmse: 0.9565 - train rmse counterfactual: 19.1816 - val_valid ite: 9.6352 - val_valid ate: 4.1818 - val_valid pehe: 10.1445 - val_valid rmse: 0.9948 - val_valid rmse counterfactual: 16.8580\n",
      "Epoch 2/100\n",
      "467/467 [==============================] - 11s 24ms/step - loss: -0.9927 - train ite: 9.8421 - train ate: 4.7330 - train pehe: 10.1016 - train rmse: 0.9524 - train rmse counterfactual: 19.1389 - val_valid ite: 9.6249 - val_valid ate: 4.1272 - val_valid pehe: 10.1221 - val_valid rmse: 0.9927 - val_valid rmse counterfactual: 16.8468\n",
      "Epoch 3/100\n",
      "467/467 [==============================] - 13s 28ms/step - loss: -0.4211 - train ite: 9.8411 - train ate: 4.7008 - train pehe: 10.0856 - train rmse: 0.9524 - train rmse counterfactual: 19.1443 - val_valid ite: 9.6102 - val_valid ate: 4.1296 - val_valid pehe: 10.1231 - val_valid rmse: 0.9937 - val_valid rmse counterfactual: 16.8059\n",
      "Epoch 4/100\n",
      "467/467 [==============================] - 16s 33ms/step - loss: -3.9349 - train ite: 9.8377 - train ate: 4.7195 - train pehe: 10.0958 - train rmse: 0.9522 - train rmse counterfactual: 19.1316 - val_valid ite: 9.6147 - val_valid ate: 4.1187 - val_valid pehe: 10.1187 - val_valid rmse: 0.9924 - val_valid rmse counterfactual: 16.8218\n",
      "Epoch 5/100\n",
      "467/467 [==============================] - 20s 42ms/step - loss: -5.0852 - train ite: 9.8403 - train ate: 4.7317 - train pehe: 10.1016 - train rmse: 0.9526 - train rmse counterfactual: 19.1341 - val_valid ite: 9.6235 - val_valid ate: 4.1559 - val_valid pehe: 10.1339 - val_valid rmse: 0.9939 - val_valid rmse counterfactual: 16.8343\n",
      "Epoch 6/100\n",
      "467/467 [==============================] - 19s 40ms/step - loss: -1.2991 - train ite: 9.8604 - train ate: 4.7523 - train pehe: 10.1121 - train rmse: 0.9543 - train rmse counterfactual: 19.1690 - val_valid ite: 9.6311 - val_valid ate: 4.1808 - val_valid pehe: 10.1441 - val_valid rmse: 0.9949 - val_valid rmse counterfactual: 16.8473\n",
      "Epoch 7/100\n",
      "467/467 [==============================] - 17s 37ms/step - loss: -3.2769 - train ite: 9.8650 - train ate: 4.7886 - train pehe: 10.1294 - train rmse: 0.9558 - train rmse counterfactual: 19.1700 - val_valid ite: 9.6500 - val_valid ate: 4.2016 - val_valid pehe: 10.1527 - val_valid rmse: 0.9960 - val_valid rmse counterfactual: 16.8917\n",
      "Epoch 8/100\n",
      "467/467 [==============================] - 14s 31ms/step - loss: -4.7120 - train ite: 9.8617 - train ate: 4.7705 - train pehe: 10.1214 - train rmse: 0.9550 - train rmse counterfactual: 19.1669 - val_valid ite: 9.6450 - val_valid ate: 4.1773 - val_valid pehe: 10.1427 - val_valid rmse: 0.9952 - val_valid rmse counterfactual: 16.8857\n",
      "Epoch 9/100\n",
      "467/467 [==============================] - 14s 31ms/step - loss: -8.5554 - train ite: 9.8596 - train ate: 4.7559 - train pehe: 10.1144 - train rmse: 0.9541 - train rmse counterfactual: 19.1664 - val_valid ite: 9.6604 - val_valid ate: 4.2457 - val_valid pehe: 10.1710 - val_valid rmse: 0.9980 - val_valid rmse counterfactual: 16.9061\n",
      "Epoch 10/100\n",
      "467/467 [==============================] - 18s 38ms/step - loss: -6.9484 - train ite: 9.8897 - train ate: 4.8254 - train pehe: 10.1483 - train rmse: 0.9586 - train rmse counterfactual: 19.2095 - val_valid ite: 9.6737 - val_valid ate: 4.3010 - val_valid pehe: 10.1943 - val_valid rmse: 1.0010 - val_valid rmse counterfactual: 16.9248\n",
      "Epoch 11/100\n",
      "467/467 [==============================] - 17s 36ms/step - loss: -5.1314 - train ite: 9.8755 - train ate: 4.8365 - train pehe: 10.1542 - train rmse: 0.9591 - train rmse counterfactual: 19.1785 - val_valid ite: 9.6229 - val_valid ate: 4.1863 - val_valid pehe: 10.1464 - val_valid rmse: 0.9967 - val_valid rmse counterfactual: 16.8234\n",
      "Epoch 12/100\n",
      "467/467 [==============================] - 17s 35ms/step - loss: -5.4260 - train ite: 9.8444 - train ate: 4.7661 - train pehe: 10.1191 - train rmse: 0.9547 - train rmse counterfactual: 19.1334 - val_valid ite: 9.6913 - val_valid ate: 4.3717 - val_valid pehe: 10.2243 - val_valid rmse: 1.0058 - val_valid rmse counterfactual: 16.9498\n",
      "Epoch 13/100\n",
      "467/467 [==============================] - 18s 38ms/step - loss: -7.7577 - train ite: 9.8916 - train ate: 4.8846 - train pehe: 10.1784 - train rmse: 0.9619 - train rmse counterfactual: 19.1987 - val_valid ite: 9.6692 - val_valid ate: 4.3272 - val_valid pehe: 10.2053 - val_valid rmse: 1.0035 - val_valid rmse counterfactual: 16.9049\n",
      "Epoch 14/100\n",
      "467/467 [==============================] - 16s 35ms/step - loss: -7.5079 - train ite: 9.8820 - train ate: 4.8433 - train pehe: 10.1578 - train rmse: 0.9594 - train rmse counterfactual: 19.1894 - val_valid ite: 9.6874 - val_valid ate: 4.3680 - val_valid pehe: 10.2227 - val_valid rmse: 1.0056 - val_valid rmse counterfactual: 16.9408\n",
      "Epoch 15/100\n",
      "467/467 [==============================] - 15s 31ms/step - loss: -10.7743 - train ite: 9.9123 - train ate: 4.9366 - train pehe: 10.2044 - train rmse: 0.9659 - train rmse counterfactual: 19.2274 - val_valid ite: 9.7265 - val_valid ate: 4.4901 - val_valid pehe: 10.2755 - val_valid rmse: 1.0153 - val_valid rmse counterfactual: 17.0059\n",
      "Epoch 16/100\n",
      "467/467 [==============================] - 17s 37ms/step - loss: -11.1042 - train ite: 9.9565 - train ate: 5.0433 - train pehe: 10.2579 - train rmse: 0.9750 - train rmse counterfactual: 19.2893 - val_valid ite: 9.7476 - val_valid ate: 4.5467 - val_valid pehe: 10.3003 - val_valid rmse: 1.0204 - val_valid rmse counterfactual: 17.0428\n",
      "Epoch 17/100\n",
      "467/467 [==============================] - 16s 35ms/step - loss: -7.0431 - train ite: 9.9872 - train ate: 5.1118 - train pehe: 10.2933 - train rmse: 0.9825 - train rmse counterfactual: 19.3318 - val_valid ite: 9.7811 - val_valid ate: 4.6416 - val_valid pehe: 10.3426 - val_valid rmse: 1.0303 - val_valid rmse counterfactual: 17.0993\n",
      "Epoch 18/100\n",
      "467/467 [==============================] - 17s 36ms/step - loss: -10.1123 - train ite: 9.9457 - train ate: 5.0047 - train pehe: 10.2379 - train rmse: 0.9715 - train rmse counterfactual: 19.2780 - val_valid ite: 9.7319 - val_valid ate: 4.4907 - val_valid pehe: 10.2757 - val_valid rmse: 1.0153 - val_valid rmse counterfactual: 17.0194\n",
      "Epoch 19/100\n",
      "467/467 [==============================] - 17s 36ms/step - loss: -11.8144 - train ite: 9.9684 - train ate: 5.0692 - train pehe: 10.2709 - train rmse: 0.9776 - train rmse counterfactual: 19.3063 - val_valid ite: 9.7542 - val_valid ate: 4.5677 - val_valid pehe: 10.3096 - val_valid rmse: 1.0225 - val_valid rmse counterfactual: 17.0535\n",
      "Epoch 20/100\n",
      "467/467 [==============================] - 17s 36ms/step - loss: -11.2541 - train ite: 9.9891 - train ate: 5.1210 - train pehe: 10.2976 - train rmse: 0.9830 - train rmse counterfactual: 19.3338 - val_valid ite: 9.8060 - val_valid ate: 4.6976 - val_valid pehe: 10.3678 - val_valid rmse: 1.0372 - val_valid rmse counterfactual: 17.1446\n",
      "Epoch 21/100\n",
      "467/467 [==============================] - 18s 37ms/step - loss: -11.8590 - train ite: 9.9904 - train ate: 5.1297 - train pehe: 10.3023 - train rmse: 0.9840 - train rmse counterfactual: 19.3343 - val_valid ite: 9.7853 - val_valid ate: 4.6458 - val_valid pehe: 10.3445 - val_valid rmse: 1.0309 - val_valid rmse counterfactual: 17.1083\n",
      "Epoch 22/100\n",
      "467/467 [==============================] - 17s 36ms/step - loss: -11.9839 - train ite: 9.9841 - train ate: 5.1203 - train pehe: 10.2976 - train rmse: 0.9832 - train rmse counterfactual: 19.3243 - val_valid ite: 9.7811 - val_valid ate: 4.6479 - val_valid pehe: 10.3454 - val_valid rmse: 1.0309 - val_valid rmse counterfactual: 17.0975\n",
      "Epoch 23/100\n",
      "467/467 [==============================] - 18s 38ms/step - loss: -12.1934 - train ite: 9.9687 - train ate: 5.0898 - train pehe: 10.2823 - train rmse: 0.9802 - train rmse counterfactual: 19.3015 - val_valid ite: 9.8107 - val_valid ate: 4.7246 - val_valid pehe: 10.3801 - val_valid rmse: 1.0400 - val_valid rmse counterfactual: 17.1485\n",
      "Epoch 24/100\n",
      "467/467 [==============================] - 14s 30ms/step - loss: -12.3626 - train ite: 9.9893 - train ate: 5.1440 - train pehe: 10.3103 - train rmse: 0.9859 - train rmse counterfactual: 19.3284 - val_valid ite: 9.8120 - val_valid ate: 4.7403 - val_valid pehe: 10.3872 - val_valid rmse: 1.0417 - val_valid rmse counterfactual: 17.1473\n",
      "Epoch 25/100\n",
      "467/467 [==============================] - 16s 34ms/step - loss: -12.7471 - train ite: 9.9685 - train ate: 5.1059 - train pehe: 10.2904 - train rmse: 0.9823 - train rmse counterfactual: 19.2977 - val_valid ite: 9.7182 - val_valid ate: 4.4830 - val_valid pehe: 10.2724 - val_valid rmse: 1.0152 - val_valid rmse counterfactual: 16.9865\n",
      "Epoch 26/100\n",
      "467/467 [==============================] - 17s 37ms/step - loss: -12.9418 - train ite: 9.9318 - train ate: 5.0244 - train pehe: 10.2489 - train rmse: 0.9750 - train rmse counterfactual: 19.2451 - val_valid ite: 9.7692 - val_valid ate: 4.6374 - val_valid pehe: 10.3407 - val_valid rmse: 1.0300 - val_valid rmse counterfactual: 17.0711\n",
      "Epoch 27/100\n",
      "467/467 [==============================] - 16s 35ms/step - loss: -13.2805 - train ite: 9.9087 - train ate: 4.9804 - train pehe: 10.2263 - train rmse: 0.9722 - train rmse counterfactual: 19.2108 - val_valid ite: 9.7309 - val_valid ate: 4.5329 - val_valid pehe: 10.2942 - val_valid rmse: 1.0201 - val_valid rmse counterfactual: 17.0046\n",
      "Epoch 28/100\n",
      "467/467 [==============================] - 17s 36ms/step - loss: -12.8628 - train ite: 9.8594 - train ate: 4.8704 - train pehe: 10.1700 - train rmse: 0.9660 - train rmse counterfactual: 19.1398 - val_valid ite: 9.6656 - val_valid ate: 4.3551 - val_valid pehe: 10.2172 - val_valid rmse: 1.0082 - val_valid rmse counterfactual: 16.8870\n",
      "Epoch 29/100\n",
      "467/467 [==============================] - 18s 39ms/step - loss: -12.9043 - train ite: 9.8442 - train ate: 4.8448 - train pehe: 10.1579 - train rmse: 0.9667 - train rmse counterfactual: 19.1145 - val_valid ite: 9.6898 - val_valid ate: 4.4375 - val_valid pehe: 10.2526 - val_valid rmse: 1.0146 - val_valid rmse counterfactual: 16.9262\n",
      "Epoch 30/100\n",
      "467/467 [==============================] - 14s 30ms/step - loss: -13.3980 - train ite: 9.8392 - train ate: 4.8432 - train pehe: 10.1555 - train rmse: 0.9673 - train rmse counterfactual: 19.1066 - val_valid ite: 9.6449 - val_valid ate: 4.3163 - val_valid pehe: 10.2007 - val_valid rmse: 1.0093 - val_valid rmse counterfactual: 16.8430\n",
      "Epoch 31/100\n",
      "467/467 [==============================] - 14s 30ms/step - loss: -13.6023 - train ite: 9.8207 - train ate: 4.7880 - train pehe: 10.1288 - train rmse: 0.9633 - train rmse counterfactual: 19.0814 - val_valid ite: 9.6467 - val_valid ate: 4.3250 - val_valid pehe: 10.2044 - val_valid rmse: 1.0102 - val_valid rmse counterfactual: 16.8453\n",
      "Epoch 32/100\n",
      "467/467 [==============================] - 16s 35ms/step - loss: -12.5281 - train ite: 9.7949 - train ate: 4.7255 - train pehe: 10.0991 - train rmse: 0.9621 - train rmse counterfactual: 19.0428 - val_valid ite: 9.6238 - val_valid ate: 4.2417 - val_valid pehe: 10.1694 - val_valid rmse: 1.0046 - val_valid rmse counterfactual: 16.8086\n",
      "Epoch 33/100\n",
      "467/467 [==============================] - 14s 30ms/step - loss: -13.1726 - train ite: 9.8096 - train ate: 4.7617 - train pehe: 10.1176 - train rmse: 0.9633 - train rmse counterfactual: 19.0632 - val_valid ite: 9.6174 - val_valid ate: 4.2272 - val_valid pehe: 10.1633 - val_valid rmse: 1.0049 - val_valid rmse counterfactual: 16.7954\n",
      "Epoch 34/100\n",
      "467/467 [==============================] - 16s 34ms/step - loss: -10.6311 - train ite: 9.7913 - train ate: 4.7261 - train pehe: 10.1018 - train rmse: 0.9651 - train rmse counterfactual: 19.0320 - val_valid ite: 9.7138 - val_valid ate: 4.5459 - val_valid pehe: 10.3000 - val_valid rmse: 1.0275 - val_valid rmse counterfactual: 16.9565\n",
      "Epoch 35/100\n",
      "467/467 [==============================] - 19s 41ms/step - loss: -12.2347 - train ite: 9.7943 - train ate: 4.7485 - train pehe: 10.1118 - train rmse: 0.9676 - train rmse counterfactual: 19.0336 - val_valid ite: 9.6363 - val_valid ate: 4.2912 - val_valid pehe: 10.1901 - val_valid rmse: 1.0083 - val_valid rmse counterfactual: 16.8274\n",
      "Epoch 36/100\n",
      "467/467 [==============================] - 17s 36ms/step - loss: -13.9652 - train ite: 9.7856 - train ate: 4.7266 - train pehe: 10.1021 - train rmse: 0.9681 - train rmse counterfactual: 19.0206 - val_valid ite: 9.6405 - val_valid ate: 4.3208 - val_valid pehe: 10.2026 - val_valid rmse: 1.0125 - val_valid rmse counterfactual: 16.8295\n",
      "Epoch 37/100\n",
      "467/467 [==============================] - 15s 32ms/step - loss: -5.0310 - train ite: 9.7944 - train ate: 4.7589 - train pehe: 10.1176 - train rmse: 0.9721 - train rmse counterfactual: 19.0315 - val_valid ite: 9.6655 - val_valid ate: 4.4135 - val_valid pehe: 10.2422 - val_valid rmse: 1.0203 - val_valid rmse counterfactual: 16.8688\n",
      "Epoch 38/100\n",
      "467/467 [==============================] - 18s 38ms/step - loss: -12.5829 - train ite: 9.8795 - train ate: 4.9662 - train pehe: 10.2193 - train rmse: 0.9779 - train rmse counterfactual: 19.1558 - val_valid ite: 9.7268 - val_valid ate: 4.5837 - val_valid pehe: 10.3167 - val_valid rmse: 1.0307 - val_valid rmse counterfactual: 16.9789\n",
      "Epoch 39/100\n",
      "467/467 [==============================] - 16s 35ms/step - loss: -13.4515 - train ite: 9.8938 - train ate: 4.9985 - train pehe: 10.2351 - train rmse: 0.9795 - train rmse counterfactual: 19.1779 - val_valid ite: 9.7294 - val_valid ate: 4.6184 - val_valid pehe: 10.3321 - val_valid rmse: 1.0380 - val_valid rmse counterfactual: 16.9752\n",
      "Epoch 40/100\n",
      "467/467 [==============================] - 17s 37ms/step - loss: -13.7796 - train ite: 9.8867 - train ate: 4.9803 - train pehe: 10.2258 - train rmse: 0.9780 - train rmse counterfactual: 19.1683 - val_valid ite: 9.7102 - val_valid ate: 4.5402 - val_valid pehe: 10.2975 - val_valid rmse: 1.0278 - val_valid rmse counterfactual: 16.9489\n",
      "Epoch 41/100\n",
      "467/467 [==============================] - 18s 38ms/step - loss: -11.7204 - train ite: 9.8759 - train ate: 4.9640 - train pehe: 10.2181 - train rmse: 0.9791 - train rmse counterfactual: 19.1492 - val_valid ite: 9.7194 - val_valid ate: 4.5815 - val_valid pehe: 10.3157 - val_valid rmse: 1.0335 - val_valid rmse counterfactual: 16.9603\n",
      "Epoch 42/100\n",
      "467/467 [==============================] - 16s 35ms/step - loss: -14.2626 - train ite: 9.8515 - train ate: 4.9152 - train pehe: 10.1927 - train rmse: 0.9782 - train rmse counterfactual: 19.1134 - val_valid ite: 9.6417 - val_valid ate: 4.3531 - val_valid pehe: 10.2163 - val_valid rmse: 1.0196 - val_valid rmse counterfactual: 16.8226\n",
      "Epoch 43/100\n",
      "467/467 [==============================] - 13s 29ms/step - loss: -14.0659 - train ite: 9.8066 - train ate: 4.7920 - train pehe: 10.1316 - train rmse: 0.9708 - train rmse counterfactual: 19.0513 - val_valid ite: 9.6314 - val_valid ate: 4.3126 - val_valid pehe: 10.1991 - val_valid rmse: 1.0160 - val_valid rmse counterfactual: 16.8070\n",
      "Epoch 44/100\n",
      "467/467 [==============================] - 17s 35ms/step - loss: -14.4390 - train ite: 9.7852 - train ate: 4.7405 - train pehe: 10.1061 - train rmse: 0.9701 - train rmse counterfactual: 19.0202 - val_valid ite: 9.6041 - val_valid ate: 4.2397 - val_valid pehe: 10.1685 - val_valid rmse: 1.0162 - val_valid rmse counterfactual: 16.7539\n",
      "Epoch 45/100\n",
      "467/467 [==============================] - 16s 34ms/step - loss: -14.6001 - train ite: 9.7561 - train ate: 4.6750 - train pehe: 10.0744 - train rmse: 0.9714 - train rmse counterfactual: 18.9751 - val_valid ite: 9.6270 - val_valid ate: 4.3203 - val_valid pehe: 10.2024 - val_valid rmse: 1.0212 - val_valid rmse counterfactual: 16.7922\n",
      "Epoch 46/100\n",
      "467/467 [==============================] - 19s 40ms/step - loss: -14.6803 - train ite: 9.7560 - train ate: 4.6753 - train pehe: 10.0747 - train rmse: 0.9714 - train rmse counterfactual: 18.9745 - val_valid ite: 9.6339 - val_valid ate: 4.3550 - val_valid pehe: 10.2171 - val_valid rmse: 1.0259 - val_valid rmse counterfactual: 16.8006\n",
      "Epoch 47/100\n",
      "467/467 [==============================] - 19s 41ms/step - loss: -13.6468 - train ite: 9.7480 - train ate: 4.6447 - train pehe: 10.0596 - train rmse: 0.9690 - train rmse counterfactual: 18.9660 - val_valid ite: 9.6102 - val_valid ate: 4.2480 - val_valid pehe: 10.1720 - val_valid rmse: 1.0139 - val_valid rmse counterfactual: 16.7685\n",
      "Epoch 48/100\n",
      "467/467 [==============================] - 17s 35ms/step - loss: -14.5048 - train ite: 9.7475 - train ate: 4.6475 - train pehe: 10.0601 - train rmse: 0.9692 - train rmse counterfactual: 18.9652 - val_valid ite: 9.5900 - val_valid ate: 4.2132 - val_valid pehe: 10.1575 - val_valid rmse: 1.0204 - val_valid rmse counterfactual: 16.7222\n",
      "Epoch 49/100\n",
      "467/467 [==============================] - 17s 36ms/step - loss: -13.2617 - train ite: 9.7813 - train ate: 4.7298 - train pehe: 10.1001 - train rmse: 0.9702 - train rmse counterfactual: 19.0151 - val_valid ite: 9.6079 - val_valid ate: 4.2488 - val_valid pehe: 10.1723 - val_valid rmse: 1.0158 - val_valid rmse counterfactual: 16.7618\n",
      "Epoch 50/100\n",
      "467/467 [==============================] - 15s 33ms/step - loss: -12.4527 - train ite: 9.8229 - train ate: 4.8362 - train pehe: 10.1521 - train rmse: 0.9731 - train rmse counterfactual: 19.0749 - val_valid ite: 9.7266 - val_valid ate: 4.6007 - val_valid pehe: 10.3243 - val_valid rmse: 1.0348 - val_valid rmse counterfactual: 16.9732\n",
      "Epoch 51/100\n",
      "467/467 [==============================] - 16s 35ms/step - loss: -11.7927 - train ite: 9.8626 - train ate: 4.9358 - train pehe: 10.2014 - train rmse: 0.9779 - train rmse counterfactual: 19.1315 - val_valid ite: 9.7206 - val_valid ate: 4.5578 - val_valid pehe: 10.3052 - val_valid rmse: 1.0274 - val_valid rmse counterfactual: 16.9706\n",
      "Epoch 52/100\n",
      "467/467 [==============================] - 16s 35ms/step - loss: -12.4976 - train ite: 9.8632 - train ate: 4.9438 - train pehe: 10.2045 - train rmse: 0.9797 - train rmse counterfactual: 19.1317 - val_valid ite: 9.6393 - val_valid ate: 4.3159 - val_valid pehe: 10.2005 - val_valid rmse: 1.0120 - val_valid rmse counterfactual: 16.8277\n",
      "Epoch 53/100\n",
      "467/467 [==============================] - 16s 34ms/step - loss: -13.2850 - train ite: 9.8838 - train ate: 4.9785 - train pehe: 10.2220 - train rmse: 0.9790 - train rmse counterfactual: 19.1637 - val_valid ite: 9.6306 - val_valid ate: 4.2918 - val_valid pehe: 10.1904 - val_valid rmse: 1.0115 - val_valid rmse counterfactual: 16.8114\n",
      "Epoch 54/100\n",
      "467/467 [==============================] - 20s 42ms/step - loss: -11.6654 - train ite: 9.8225 - train ate: 4.8487 - train pehe: 10.1582 - train rmse: 0.9765 - train rmse counterfactual: 19.0694 - val_valid ite: 9.5838 - val_valid ate: 4.1957 - val_valid pehe: 10.1503 - val_valid rmse: 1.0207 - val_valid rmse counterfactual: 16.7101\n",
      "Epoch 55/100\n",
      "467/467 [==============================] - 18s 38ms/step - loss: -13.8415 - train ite: 9.8007 - train ate: 4.8161 - train pehe: 10.1421 - train rmse: 0.9802 - train rmse counterfactual: 19.0319 - val_valid ite: 9.5669 - val_valid ate: 4.1223 - val_valid pehe: 10.1202 - val_valid rmse: 1.0145 - val_valid rmse counterfactual: 16.6852\n",
      "Epoch 56/100\n",
      "467/467 [==============================] - 17s 36ms/step - loss: -13.3457 - train ite: 9.7980 - train ate: 4.8183 - train pehe: 10.1436 - train rmse: 0.9824 - train rmse counterfactual: 19.0259 - val_valid ite: 9.6435 - val_valid ate: 4.3596 - val_valid pehe: 10.2191 - val_valid rmse: 1.0201 - val_valid rmse counterfactual: 16.8256\n",
      "Epoch 57/100\n",
      "467/467 [==============================] - 13s 29ms/step - loss: -14.7220 - train ite: 9.8301 - train ate: 4.8957 - train pehe: 10.1819 - train rmse: 0.9840 - train rmse counterfactual: 19.0736 - val_valid ite: 9.6166 - val_valid ate: 4.2828 - val_valid pehe: 10.1866 - val_valid rmse: 1.0185 - val_valid rmse counterfactual: 16.7754\n",
      "Epoch 58/100\n",
      "467/467 [==============================] - 15s 31ms/step - loss: -14.9597 - train ite: 9.8142 - train ate: 4.8543 - train pehe: 10.1616 - train rmse: 0.9823 - train rmse counterfactual: 19.0503 - val_valid ite: 9.5950 - val_valid ate: 4.2044 - val_valid pehe: 10.1539 - val_valid rmse: 1.0138 - val_valid rmse counterfactual: 16.7395\n",
      "Epoch 59/100\n",
      "467/467 [==============================] - 18s 38ms/step - loss: -14.2418 - train ite: 9.8226 - train ate: 4.8737 - train pehe: 10.1718 - train rmse: 0.9828 - train rmse counterfactual: 19.0626 - val_valid ite: 9.6869 - val_valid ate: 4.4940 - val_valid pehe: 10.2772 - val_valid rmse: 1.0285 - val_valid rmse counterfactual: 16.9013\n",
      "Epoch 60/100\n",
      "467/467 [==============================] - 19s 41ms/step - loss: -15.0560 - train ite: 9.8211 - train ate: 4.8631 - train pehe: 10.1661 - train rmse: 0.9805 - train rmse counterfactual: 19.0631 - val_valid ite: 9.6301 - val_valid ate: 4.3136 - val_valid pehe: 10.1996 - val_valid rmse: 1.0171 - val_valid rmse counterfactual: 16.8032\n",
      "Epoch 61/100\n",
      "467/467 [==============================] - 16s 34ms/step - loss: -15.2049 - train ite: 9.8075 - train ate: 4.8278 - train pehe: 10.1481 - train rmse: 0.9787 - train rmse counterfactual: 19.0444 - val_valid ite: 9.6243 - val_valid ate: 4.3082 - val_valid pehe: 10.1973 - val_valid rmse: 1.0198 - val_valid rmse counterfactual: 16.7886\n",
      "Epoch 62/100\n",
      "467/467 [==============================] - 14s 31ms/step - loss: -15.6625 - train ite: 9.7748 - train ate: 4.7473 - train pehe: 10.1083 - train rmse: 0.9774 - train rmse counterfactual: 18.9963 - val_valid ite: 9.6415 - val_valid ate: 4.3541 - val_valid pehe: 10.2167 - val_valid rmse: 1.0201 - val_valid rmse counterfactual: 16.8217\n",
      "Epoch 63/100\n",
      "467/467 [==============================] - 17s 36ms/step - loss: -14.4208 - train ite: 9.8151 - train ate: 4.8526 - train pehe: 10.1600 - train rmse: 0.9819 - train rmse counterfactual: 19.0547 - val_valid ite: 9.6371 - val_valid ate: 4.3239 - val_valid pehe: 10.2039 - val_valid rmse: 1.0151 - val_valid rmse counterfactual: 16.8194\n",
      "Epoch 64/100\n",
      "467/467 [==============================] - 15s 32ms/step - loss: -15.5448 - train ite: 9.8511 - train ate: 4.9331 - train pehe: 10.1997 - train rmse: 0.9825 - train rmse counterfactual: 19.1089 - val_valid ite: 9.6491 - val_valid ate: 4.3891 - val_valid pehe: 10.2317 - val_valid rmse: 1.0244 - val_valid rmse counterfactual: 16.8316\n",
      "Epoch 65/100\n",
      "467/467 [==============================] - 13s 28ms/step - loss: -15.4671 - train ite: 9.8602 - train ate: 4.9525 - train pehe: 10.2090 - train rmse: 0.9828 - train rmse counterfactual: 19.1233 - val_valid ite: 9.6741 - val_valid ate: 4.4175 - val_valid pehe: 10.2440 - val_valid rmse: 1.0168 - val_valid rmse counterfactual: 16.8905\n",
      "Epoch 66/100\n",
      "467/467 [==============================] - 15s 32ms/step - loss: -15.7637 - train ite: 9.8294 - train ate: 4.8753 - train pehe: 10.1704 - train rmse: 0.9790 - train rmse counterfactual: 19.0794 - val_valid ite: 9.6502 - val_valid ate: 4.3571 - val_valid pehe: 10.2181 - val_valid rmse: 1.0154 - val_valid rmse counterfactual: 16.8448\n",
      "Epoch 67/100\n",
      "467/467 [==============================] - 13s 29ms/step - loss: -15.6326 - train ite: 9.8331 - train ate: 4.8797 - train pehe: 10.1723 - train rmse: 0.9780 - train rmse counterfactual: 19.0866 - val_valid ite: 9.6280 - val_valid ate: 4.2748 - val_valid pehe: 10.1832 - val_valid rmse: 1.0091 - val_valid rmse counterfactual: 16.8097\n",
      "Epoch 68/100\n",
      "467/467 [==============================] - 15s 32ms/step - loss: -15.8293 - train ite: 9.8434 - train ate: 4.9018 - train pehe: 10.1836 - train rmse: 0.9784 - train rmse counterfactual: 19.1016 - val_valid ite: 9.6108 - val_valid ate: 4.2453 - val_valid pehe: 10.1709 - val_valid rmse: 1.0129 - val_valid rmse counterfactual: 16.7709\n",
      "Epoch 69/100\n",
      "467/467 [==============================] - 14s 30ms/step - loss: -14.3477 - train ite: 9.8477 - train ate: 4.9089 - train pehe: 10.1883 - train rmse: 0.9787 - train rmse counterfactual: 19.1069 - val_valid ite: 9.7608 - val_valid ate: 4.6776 - val_valid pehe: 10.3588 - val_valid rmse: 1.0390 - val_valid rmse counterfactual: 17.0380\n",
      "Epoch 70/100\n",
      "467/467 [==============================] - 13s 28ms/step - loss: -10.4300 - train ite: 9.8358 - train ate: 4.9120 - train pehe: 10.1902 - train rmse: 0.9883 - train rmse counterfactual: 19.0807 - val_valid ite: 9.6179 - val_valid ate: 4.2438 - val_valid pehe: 10.1703 - val_valid rmse: 1.0081 - val_valid rmse counterfactual: 16.7913\n",
      "Epoch 71/100\n",
      "467/467 [==============================] - 19s 40ms/step - loss: -13.7106 - train ite: 9.8571 - train ate: 4.9062 - train pehe: 10.1870 - train rmse: 0.9735 - train rmse counterfactual: 19.1270 - val_valid ite: 9.6600 - val_valid ate: 4.3640 - val_valid pehe: 10.2210 - val_valid rmse: 1.0120 - val_valid rmse counterfactual: 16.8692\n",
      "Epoch 72/100\n",
      "467/467 [==============================] - 13s 28ms/step - loss: -15.1687 - train ite: 9.8918 - train ate: 5.0123 - train pehe: 10.2405 - train rmse: 0.9832 - train rmse counterfactual: 19.1710 - val_valid ite: 9.6816 - val_valid ate: 4.4385 - val_valid pehe: 10.2530 - val_valid rmse: 1.0179 - val_valid rmse counterfactual: 16.9042\n",
      "Epoch 73/100\n",
      "467/467 [==============================] - 16s 34ms/step - loss: -15.2914 - train ite: 9.9128 - train ate: 5.0585 - train pehe: 10.2642 - train rmse: 0.9858 - train rmse counterfactual: 19.2015 - val_valid ite: 9.6899 - val_valid ate: 4.4583 - val_valid pehe: 10.2616 - val_valid rmse: 1.0185 - val_valid rmse counterfactual: 16.9203\n",
      "Epoch 74/100\n",
      "467/467 [==============================] - 20s 43ms/step - loss: -15.2966 - train ite: 9.9068 - train ate: 5.0578 - train pehe: 10.2640 - train rmse: 0.9883 - train rmse counterfactual: 19.1895 - val_valid ite: 9.6930 - val_valid ate: 4.4930 - val_valid pehe: 10.2767 - val_valid rmse: 1.0249 - val_valid rmse counterfactual: 16.9178\n",
      "Epoch 75/100\n",
      "467/467 [==============================] - 12s 26ms/step - loss: -15.5190 - train ite: 9.8798 - train ate: 4.9869 - train pehe: 10.2280 - train rmse: 0.9829 - train rmse counterfactual: 19.1526 - val_valid ite: 9.6474 - val_valid ate: 4.3614 - val_valid pehe: 10.2199 - val_valid rmse: 1.0181 - val_valid rmse counterfactual: 16.8357\n",
      "Epoch 76/100\n",
      "467/467 [==============================] - 18s 38ms/step - loss: -15.9815 - train ite: 9.8460 - train ate: 4.9037 - train pehe: 10.1861 - train rmse: 0.9781 - train rmse counterfactual: 19.1044 - val_valid ite: 9.6976 - val_valid ate: 4.4954 - val_valid pehe: 10.2778 - val_valid rmse: 1.0233 - val_valid rmse counterfactual: 16.9292\n",
      "Epoch 77/100\n",
      "467/467 [==============================] - 19s 41ms/step - loss: -15.9739 - train ite: 9.8716 - train ate: 4.9657 - train pehe: 10.2182 - train rmse: 0.9811 - train rmse counterfactual: 19.1406 - val_valid ite: 9.6551 - val_valid ate: 4.3783 - val_valid pehe: 10.2271 - val_valid rmse: 1.0177 - val_valid rmse counterfactual: 16.8515\n",
      "Epoch 78/100\n",
      "467/467 [==============================] - 15s 31ms/step - loss: -15.9171 - train ite: 9.8319 - train ate: 4.8702 - train pehe: 10.1700 - train rmse: 0.9768 - train rmse counterfactual: 19.0832 - val_valid ite: 9.6586 - val_valid ate: 4.3934 - val_valid pehe: 10.2336 - val_valid rmse: 1.0193 - val_valid rmse counterfactual: 16.8563\n",
      "Epoch 79/100\n",
      "467/467 [==============================] - 18s 39ms/step - loss: -16.0587 - train ite: 9.8159 - train ate: 4.8367 - train pehe: 10.1531 - train rmse: 0.9770 - train rmse counterfactual: 19.0592 - val_valid ite: 9.6091 - val_valid ate: 4.2315 - val_valid pehe: 10.1651 - val_valid rmse: 1.0106 - val_valid rmse counterfactual: 16.7708\n",
      "Epoch 80/100\n",
      "467/467 [==============================] - 25s 53ms/step - loss: -16.0395 - train ite: 9.7930 - train ate: 4.7745 - train pehe: 10.1217 - train rmse: 0.9739 - train rmse counterfactual: 19.0283 - val_valid ite: 9.6247 - val_valid ate: 4.2927 - val_valid pehe: 10.1907 - val_valid rmse: 1.0154 - val_valid rmse counterfactual: 16.7947\n",
      "Epoch 81/100\n",
      "467/467 [==============================] - 17s 36ms/step - loss: -15.9462 - train ite: 9.8027 - train ate: 4.8025 - train pehe: 10.1358 - train rmse: 0.9755 - train rmse counterfactual: 19.0410 - val_valid ite: 9.6448 - val_valid ate: 4.3486 - val_valid pehe: 10.2144 - val_valid rmse: 1.0165 - val_valid rmse counterfactual: 16.8325\n",
      "Epoch 82/100\n",
      "467/467 [==============================] - 20s 43ms/step - loss: -10.0372 - train ite: 9.7911 - train ate: 4.7798 - train pehe: 10.1268 - train rmse: 0.9806 - train rmse counterfactual: 19.0208 - val_valid ite: 9.5684 - val_valid ate: 4.1265 - val_valid pehe: 10.1219 - val_valid rmse: 1.0143 - val_valid rmse counterfactual: 16.6882\n",
      "Epoch 83/100\n",
      "467/467 [==============================] - 26s 55ms/step - loss: -10.8658 - train ite: 9.7990 - train ate: 4.7981 - train pehe: 10.1337 - train rmse: 0.9767 - train rmse counterfactual: 19.0341 - val_valid ite: 9.6021 - val_valid ate: 4.2493 - val_valid pehe: 10.1726 - val_valid rmse: 1.0206 - val_valid rmse counterfactual: 16.7450\n",
      "Epoch 84/100\n",
      "467/467 [==============================] - 22s 47ms/step - loss: -12.6948 - train ite: 9.8148 - train ate: 4.8235 - train pehe: 10.1460 - train rmse: 0.9734 - train rmse counterfactual: 19.0608 - val_valid ite: 9.6016 - val_valid ate: 4.2015 - val_valid pehe: 10.1527 - val_valid rmse: 1.0084 - val_valid rmse counterfactual: 16.7591\n",
      "Epoch 85/100\n",
      "467/467 [==============================] - 18s 39ms/step - loss: -9.9956 - train ite: 9.8645 - train ate: 4.9277 - train pehe: 10.1989 - train rmse: 0.9753 - train rmse counterfactual: 19.1359 - val_valid ite: 9.6873 - val_valid ate: 4.4698 - val_valid pehe: 10.2666 - val_valid rmse: 1.0222 - val_valid rmse counterfactual: 16.9099\n",
      "Epoch 86/100\n",
      "467/467 [==============================] - 21s 46ms/step - loss: -14.3904 - train ite: 9.8976 - train ate: 5.0296 - train pehe: 10.2486 - train rmse: 0.9842 - train rmse counterfactual: 19.1791 - val_valid ite: 9.6509 - val_valid ate: 4.3728 - val_valid pehe: 10.2247 - val_valid rmse: 1.0188 - val_valid rmse counterfactual: 16.8417\n",
      "Epoch 87/100\n",
      "467/467 [==============================] - 17s 37ms/step - loss: -13.3523 - train ite: 9.8814 - train ate: 4.9973 - train pehe: 10.2325 - train rmse: 0.9838 - train rmse counterfactual: 19.1543 - val_valid ite: 9.6782 - val_valid ate: 4.4569 - val_valid pehe: 10.2610 - val_valid rmse: 1.0239 - val_valid rmse counterfactual: 16.8893\n",
      "Epoch 88/100\n",
      "467/467 [==============================] - 20s 42ms/step - loss: -15.5967 - train ite: 9.8952 - train ate: 5.0400 - train pehe: 10.2548 - train rmse: 0.9886 - train rmse counterfactual: 19.1707 - val_valid ite: 9.6658 - val_valid ate: 4.4165 - val_valid pehe: 10.2435 - val_valid rmse: 1.0209 - val_valid rmse counterfactual: 16.8685\n",
      "Epoch 89/100\n",
      "467/467 [==============================] - 20s 43ms/step - loss: -15.4579 - train ite: 9.8901 - train ate: 5.0301 - train pehe: 10.2503 - train rmse: 0.9885 - train rmse counterfactual: 19.1626 - val_valid ite: 9.6982 - val_valid ate: 4.5179 - val_valid pehe: 10.2877 - val_valid rmse: 1.0283 - val_valid rmse counterfactual: 16.9241\n",
      "Epoch 90/100\n",
      "467/467 [==============================] - 22s 47ms/step - loss: -15.2971 - train ite: 9.8784 - train ate: 5.0040 - train pehe: 10.2372 - train rmse: 0.9874 - train rmse counterfactual: 19.1452 - val_valid ite: 9.6529 - val_valid ate: 4.3825 - val_valid pehe: 10.2289 - val_valid rmse: 1.0200 - val_valid rmse counterfactual: 16.8441\n",
      "Epoch 91/100\n",
      "467/467 [==============================] - 20s 42ms/step - loss: -15.8717 - train ite: 9.8760 - train ate: 4.9952 - train pehe: 10.2329 - train rmse: 0.9864 - train rmse counterfactual: 19.1424 - val_valid ite: 9.6792 - val_valid ate: 4.4600 - val_valid pehe: 10.2623 - val_valid rmse: 1.0241 - val_valid rmse counterfactual: 16.8913\n",
      "Epoch 92/100\n",
      "467/467 [==============================] - 15s 32ms/step - loss: -15.4881 - train ite: 9.8705 - train ate: 4.9782 - train pehe: 10.2244 - train rmse: 0.9847 - train rmse counterfactual: 19.1354 - val_valid ite: 9.7024 - val_valid ate: 4.5277 - val_valid pehe: 10.2919 - val_valid rmse: 1.0286 - val_valid rmse counterfactual: 16.9321\n",
      "Epoch 93/100\n",
      "467/467 [==============================] - 17s 36ms/step - loss: -13.2181 - train ite: 9.8838 - train ate: 5.0113 - train pehe: 10.2412 - train rmse: 0.9892 - train rmse counterfactual: 19.1559 - val_valid ite: 9.6213 - val_valid ate: 4.2913 - val_valid pehe: 10.1901 - val_valid rmse: 1.0173 - val_valid rmse counterfactual: 16.7858\n",
      "Epoch 94/100\n",
      "467/467 [==============================] - 14s 29ms/step - loss: -8.6342 - train ite: 9.8144 - train ate: 4.8312 - train pehe: 10.1489 - train rmse: 0.9775 - train rmse counterfactual: 19.0588 - val_valid ite: 9.5740 - val_valid ate: 4.1112 - val_valid pehe: 10.1156 - val_valid rmse: 1.0062 - val_valid rmse counterfactual: 16.7095\n",
      "Epoch 95/100\n",
      "467/467 [==============================] - 18s 38ms/step - loss: -13.6038 - train ite: 9.8571 - train ate: 4.9267 - train pehe: 10.1975 - train rmse: 0.9779 - train rmse counterfactual: 19.1214 - val_valid ite: 9.6330 - val_valid ate: 4.3071 - val_valid pehe: 10.1968 - val_valid rmse: 1.0136 - val_valid rmse counterfactual: 16.8133\n",
      "Epoch 96/100\n",
      "467/467 [==============================] - 22s 47ms/step - loss: -13.5744 - train ite: 9.8814 - train ate: 5.0052 - train pehe: 10.2377 - train rmse: 0.9863 - train rmse counterfactual: 19.1508 - val_valid ite: 9.6297 - val_valid ate: 4.3384 - val_valid pehe: 10.2101 - val_valid rmse: 1.0243 - val_valid rmse counterfactual: 16.7940\n",
      "Epoch 97/100\n",
      "467/467 [==============================] - 18s 38ms/step - loss: -14.0609 - train ite: 9.8611 - train ate: 4.9798 - train pehe: 10.2257 - train rmse: 0.9909 - train rmse counterfactual: 19.1146 - val_valid ite: 9.6895 - val_valid ate: 4.5187 - val_valid pehe: 10.2880 - val_valid rmse: 1.0337 - val_valid rmse counterfactual: 16.9007\n",
      "Epoch 98/100\n",
      "467/467 [==============================] - 21s 45ms/step - loss: -13.0990 - train ite: 9.8292 - train ate: 4.8918 - train pehe: 10.1807 - train rmse: 0.9843 - train rmse counterfactual: 19.0723 - val_valid ite: 9.6135 - val_valid ate: 4.2918 - val_valid pehe: 10.1904 - val_valid rmse: 1.0237 - val_valid rmse counterfactual: 16.7635\n",
      "Epoch 99/100\n",
      "467/467 [==============================] - 26s 56ms/step - loss: -14.7646 - train ite: 9.8359 - train ate: 4.9170 - train pehe: 10.1936 - train rmse: 0.9870 - train rmse counterfactual: 19.0795 - val_valid ite: 9.6656 - val_valid ate: 4.4446 - val_valid pehe: 10.2557 - val_valid rmse: 1.0286 - val_valid rmse counterfactual: 16.8592\n",
      "Epoch 100/100\n",
      "467/467 [==============================] - 18s 39ms/step - loss: -15.8958 - train ite: 9.8464 - train ate: 4.9512 - train pehe: 10.2108 - train rmse: 0.9906 - train rmse counterfactual: 19.0928 - val_valid ite: 9.6765 - val_valid ate: 4.4906 - val_valid pehe: 10.2757 - val_valid rmse: 1.0344 - val_valid rmse counterfactual: 16.8745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1351ce580>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"fit_logs/\", histogram_freq=1)\n",
    "train_dataset = input_fn_csv(\"./datasets/IHDP/csv_create\",'train')\n",
    "valid_dataset = input_fn_csv(\"./datasets/IHDP/csv_create\",'valid')\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = valid_dataset, \n",
    "    callbacks=[tensorboard_callback],\n",
    "    epochs = args.epochs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.losses import Loss\n",
    "def make_aipw(input_dim, reg_l2):\n",
    "\n",
    "    x = Input(shape=(input_dim,), name='input')\n",
    "    # representation\n",
    "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_1')(x)\n",
    "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_2')(phi)\n",
    "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_3')(phi)\n",
    "\n",
    "    # HYPOTHESIS\n",
    "    y0_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_1')(phi)\n",
    "    y1_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_1')(phi)\n",
    "\n",
    "    # second layer\n",
    "    y0_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_2')(y0_hidden)\n",
    "    y1_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_2')(y1_hidden)\n",
    "\n",
    "    # third\n",
    "    y0_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y0_predictions')(y0_hidden)\n",
    "    y1_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y1_predictions')(y1_hidden)\n",
    "\n",
    "    #propensity prediction\n",
    "    #Note that the activation is actually sigmoid, but we will squish it in the loss function for numerical stability reasons\n",
    "    t_prediction = Dense(units=1,activation=None,name='t_prediction')(phi)\n",
    "\n",
    "    concat_pred = Concatenate(1)([y0_predictions, y1_predictions,t_prediction,phi])\n",
    "    model = Model(inputs=x, outputs=concat_pred)\n",
    "    return model\n",
    "\n",
    "class Base_Loss(Loss):\n",
    "    #initialize instance attributes\n",
    "    def __init__(self, alpha=1.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.name='standard_loss'\n",
    "\n",
    "    def split_pred(self,concat_pred):\n",
    "        #generic helper to make sure we dont make mistakes\n",
    "        preds={}\n",
    "        preds['y0_pred'] = concat_pred[:, 0]\n",
    "        preds['y1_pred'] = concat_pred[:, 1]\n",
    "        preds['t_pred'] = concat_pred[:, 2]\n",
    "        preds['phi'] = concat_pred[:, 3:]\n",
    "        return preds\n",
    "\n",
    "    #for logging purposes only\n",
    "    def treatment_acc(self,concat_true,concat_pred):\n",
    "        t_true = concat_true[:, 1]\n",
    "        p = self.split_pred(concat_pred)\n",
    "        #Since this isn't used as a loss, I've used tf.reduce_mean for interpretability\n",
    "        return tf.reduce_mean(binary_accuracy(t_true, tf.math.sigmoid(p['t_pred']), threshold=0.5))\n",
    "\n",
    "    def treatment_bce(self,concat_true,concat_pred):\n",
    "        t_true = concat_true[:, 1]\n",
    "        p = self.split_pred(concat_pred)\n",
    "        lossP = tf.reduce_sum(binary_crossentropy(t_true,p['t_pred'],from_logits=True))\n",
    "        return lossP\n",
    "    \n",
    "    def regression_loss(self,concat_true,concat_pred):\n",
    "        y_true = concat_true[:, 0]\n",
    "        t_true = concat_true[:, 1]\n",
    "        p = self.split_pred(concat_pred)\n",
    "        loss0 = tf.reduce_sum((1. - t_true) * tf.square(y_true - p['y0_pred']))\n",
    "        loss1 = tf.reduce_sum(t_true * tf.square(y_true - p['y1_pred']))\n",
    "        return loss0+loss1\n",
    "\n",
    "    def standard_loss(self,concat_true,concat_pred):\n",
    "        lossR = self.regression_loss(concat_true,concat_pred)\n",
    "        lossP = self.treatment_bce(concat_true,concat_pred)\n",
    "        return lossR + self.alpha * lossP\n",
    "\n",
    "    #compute loss\n",
    "    def call(self, concat_true, concat_pred):        \n",
    "        return self.standard_loss(concat_true,concat_pred)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "def pdist2sq(A, B):\n",
    "    #helper for PEHEnn\n",
    "    #calculates squared euclidean distance between rows of two matrices  \n",
    "    #https://gist.github.com/mbsariyildiz/34cdc26afb630e8cae079048eef91865\n",
    "    # squared norms of each row in A and B\n",
    "    na = tf.reduce_sum(tf.square(A), 1)\n",
    "    nb = tf.reduce_sum(tf.square(B), 1)    \n",
    "    # na as a row and nb as a column vectors\n",
    "    na = tf.reshape(na, [-1, 1])\n",
    "    nb = tf.reshape(nb, [1, -1])\n",
    "    # return pairwise euclidean difference matrix\n",
    "    D=tf.reduce_sum((tf.expand_dims(A, 1)-tf.expand_dims(B, 0))**2,2) \n",
    "    return D\n",
    "\n",
    "#https://towardsdatascience.com/implementing-macro-f1-score-in-keras-what-not-to-do-e9f1aa04029d\n",
    "class AIPW_Metrics(Callback):\n",
    "    def __init__(self,data, verbose=0):   \n",
    "        super(AIPW_Metrics, self).__init__()\n",
    "        self.data=data #feed the callback the full dataset\n",
    "        self.verbose=verbose\n",
    "\n",
    "        #needed for PEHEnn; Called in self.find_ynn\n",
    "        self.data['o_idx']=tf.range(self.data['t'].shape[0])\n",
    "        self.data['c_idx']=self.data['o_idx'][self.data['t'].squeeze()==0] #These are the indices of the control units\n",
    "        self.data['t_idx']=self.data['o_idx'][self.data['t'].squeeze()==1] #These are the indices of the treated units\n",
    "    \n",
    "    def split_pred(self,concat_pred):\n",
    "        preds={}\n",
    "        preds['y0_pred'] = self.data['y_scaler'].inverse_transform(np.reshape(concat_pred[:, 0],[-1,1]))[:,0]\n",
    "        preds['y1_pred'] = self.data['y_scaler'].inverse_transform(np.reshape(concat_pred[:, 1],[-1,1]))[:,0]\n",
    "        preds['t_pred'] = concat_pred[:, 2]\n",
    "        preds['phi'] = concat_pred[:, 3:]\n",
    "        return preds\n",
    "\n",
    "    def find_ynn(self, Phi):\n",
    "        #helper for PEHEnn\n",
    "        PhiC, PhiT =tf.dynamic_partition(Phi,tf.cast(tf.squeeze(self.data['t']),tf.int32),2) #separate control and treated reps\n",
    "        dists=tf.sqrt(pdist2sq(PhiC,PhiT)) #calculate squared distance then sqrt to get euclidean\n",
    "        yT_nn_idx=tf.gather(self.data['c_idx'],tf.argmin(dists,axis=0),1) #get c_idxs of smallest distances for treated units\n",
    "        yC_nn_idx=tf.gather(self.data['t_idx'],tf.argmin(dists,axis=1),1) #get t_idxs of smallest distances for control units\n",
    "        yT_nn=tf.gather(self.data['y'],yT_nn_idx,1) #now use these to retrieve y values\n",
    "        yC_nn=tf.gather(self.data['y'],yC_nn_idx,1)\n",
    "        y_nn=tf.dynamic_stitch([self.data['t_idx'],self.data['c_idx']],[yT_nn,yC_nn]) #stitch em back up!\n",
    "        return y_nn\n",
    "\n",
    "    def PEHEnn(self,concat_pred):\n",
    "        p = self.split_pred(concat_pred)\n",
    "        y_nn = self.find_ynn(p['phi']) #now its 3 plus because \n",
    "        cate_nn_err=tf.reduce_mean( tf.square( (1-2*self.data['t']) * (y_nn-self.data['y']) - (p['y1_pred']-p['y0_pred']) ) )\n",
    "        return cate_nn_err\n",
    "\n",
    "    def ATE(self,concat_pred):\n",
    "        p = self.split_pred(concat_pred)\n",
    "        return p['y1_pred']-p['y0_pred']\n",
    "\n",
    "    def PEHE(self,concat_pred):\n",
    "        #simulation only\n",
    "        p = self.split_pred(concat_pred)\n",
    "        cate_err=tf.reduce_mean( tf.square( ( (self.data['mu_1']-self.data['mu_0']) - (p['y1_pred']-p['y0_pred']) ) ) )\n",
    "        return cate_err \n",
    "   \n",
    "    #THIS IS THE NEW PART\n",
    "    def AIPW(self,concat_pred):\n",
    "        p = self.split_pred(concat_pred)\n",
    "        t_pred=tf.math.sigmoid(p['t_pred'])\n",
    "        t_pred = (t_pred + 0.001) / 1.002 # a little numerical stability trick implemented by Shi\n",
    "        y_pred = p['y0_pred'] * (1 - self.data['t']) + p['y1_pred'] * self.data['t']\n",
    "        #cc stands for clever covariate which is I think what it's called in TMLE lit\n",
    "        cc = self.data['t'] * (1.0 / p['t_pred']) - (1.0 - self.data['t']) / (1.0 - p['t_pred'])\n",
    "        cate = cc * (self.data['y'] - y_pred) + p['y1_pred'] - p['y0_pred']\n",
    "        return cate\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        concat_pred=self.model.predict(self.data['x'])\n",
    "        #Calculate Empirical Metrics        \n",
    "        ate_pred=tf.reduce_mean(self.ATE(concat_pred)); tf.summary.scalar('ate', data=ate_pred, step=epoch)\n",
    "        pehe_nn=self.PEHEnn(concat_pred); tf.summary.scalar('cate_nn_err', data=tf.sqrt(pehe_nn), step=epoch)\n",
    "        aipw=tf.reduce_mean(self.AIPW(concat_pred)); tf.summary.scalar('aipw', data=aipw, step=epoch)\n",
    "        \n",
    "        #Simulation Metrics\n",
    "        ate_true=tf.reduce_mean(self.data['mu_1']-self.data['mu_0'])\n",
    "        ate_err=tf.abs(ate_true-ate_pred); tf.summary.scalar('ate_err', data=ate_err, step=epoch)\n",
    "        pehe =self.PEHE(concat_pred); tf.summary.scalar('cate_err', data=tf.sqrt(pehe), step=epoch)\n",
    "        aipw_err =self.PEHE(concat_pred); tf.summary.scalar('aipw_err', data=aipw_err, step=epoch)\n",
    "        out_str=f' — ate_err: {ate_err:.4f}  — aipw_err: {aipw_err:.4f} — cate_err: {tf.sqrt(pehe):.4f} — cate_nn_err: {tf.sqrt(pehe_nn):.4f} '\n",
    "        \n",
    "        if self.verbose > 0: print(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 “ihdp_npci_1-100.train.npz” 已经存在；不获取。\n",
      "\n",
      "文件 “ihdp_npci_1-100.test.npz” 已经存在；不获取。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title First load the data! (Click Play)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "!wget -nc http://www.fredjo.com/files/ihdp_npci_1-100.train.npz\n",
    "!wget -nc http://www.fredjo.com/files/ihdp_npci_1-100.test.npz \n",
    "\n",
    "def load_IHDP_data(training_data,testing_data,i=7):\n",
    "    with open(training_data,'rb') as trf, open(testing_data,'rb') as tef:\n",
    "        train_data=np.load(trf); test_data=np.load(tef)\n",
    "        y=np.concatenate(   (train_data['yf'][:,i],   test_data['yf'][:,i])).astype('float32') #most GPUs only compute 32-bit floats\n",
    "        t=np.concatenate(   (train_data['t'][:,i],    test_data['t'][:,i])).astype('float32')\n",
    "        x=np.concatenate(   (train_data['x'][:,:,i],  test_data['x'][:,:,i]),axis=0).astype('float32')\n",
    "        mu_0=np.concatenate((train_data['mu0'][:,i],  test_data['mu0'][:,i])).astype('float32')\n",
    "        mu_1=np.concatenate((train_data['mu1'][:,i],  test_data['mu1'][:,i])).astype('float32')\n",
    "\n",
    "        data={'x':x,'t':t,'y':y,'t':t,'mu_0':mu_0,'mu_1':mu_1}\n",
    "        data['t']=data['t'].reshape(-1,1) #we're just padding one dimensional vectors with an additional dimension \n",
    "        data['y']=data['y'].reshape(-1,1)\n",
    "        \n",
    "        #rescaling y between 0 and 1 often makes training of DL regressors easier\n",
    "        data['y_scaler'] = StandardScaler().fit(data['y'])\n",
    "        data['ys'] = data['y_scaler'].transform(data['y'])\n",
    "\n",
    "    return data\n",
    "\n",
    "data=load_IHDP_data(training_data='./ihdp_npci_1-100.train.npz',testing_data='./ihdp_npci_1-100.test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      " 1/10 [==>...........................] - ETA: 9s - loss: 79.1230 - standard_loss: 74.4222 - regression_loss: 73.7230 - treatment_acc: 0.5156WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0061s). Check your callbacks.\n",
      " — ate_err: 3.1883  — aipw_err: 12.2204 — cate_err: 3.4958 — cate_nn_err: 3.9366 \n",
      "10/10 [==============================] - 2s 73ms/step - loss: 65.0354 - standard_loss: 57.7367 - regression_loss: 57.0393 - treatment_acc: 0.4693 - val_loss: 65.7695 - val_standard_loss: 54.2041 - val_regression_loss: 53.5072 - val_treatment_acc: 0.4432 - lr: 1.0000e-05\n",
      "Epoch 2/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 56.0141 - standard_loss: 51.3135 - regression_loss: 50.6178 - treatment_acc: 0.4688 — ate_err: 2.3751  — aipw_err: 7.3794 — cate_err: 2.7165 — cate_nn_err: 3.3591 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 53.2539 - standard_loss: 47.2544 - regression_loss: 46.5581 - treatment_acc: 0.4804 - val_loss: 56.0254 - val_standard_loss: 45.8025 - val_regression_loss: 45.1059 - val_treatment_acc: 0.4432 - lr: 1.0000e-05\n",
      "Epoch 3/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 55.2391 - standard_loss: 50.5385 - regression_loss: 49.8541 - treatment_acc: 0.6250 — ate_err: 1.7427  — aipw_err: 4.4949 — cate_err: 2.1201 — cate_nn_err: 2.9936 \n",
      "10/10 [==============================] - 0s 38ms/step - loss: 44.6807 - standard_loss: 38.5318 - regression_loss: 37.8360 - treatment_acc: 0.4851 - val_loss: 47.6086 - val_standard_loss: 38.4802 - val_regression_loss: 37.7834 - val_treatment_acc: 0.4531 - lr: 1.0000e-05\n",
      "Epoch 4/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 34.2255 - standard_loss: 29.5247 - regression_loss: 28.8280 - treatment_acc: 0.4844 — ate_err: 1.2675  — aipw_err: 2.8809 — cate_err: 1.6973 — cate_nn_err: 2.8046 \n",
      "10/10 [==============================] - 0s 45ms/step - loss: 37.3796 - standard_loss: 31.5620 - regression_loss: 30.8670 - treatment_acc: 0.4804 - val_loss: 41.8220 - val_standard_loss: 33.3964 - val_regression_loss: 32.6995 - val_treatment_acc: 0.4735 - lr: 1.0000e-05\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - ETA: 0s - loss: 33.4020 - standard_loss: 27.2861 - regression_loss: 26.5908 - treatment_acc: 0.4868 — ate_err: 0.9381  — aipw_err: 2.0326 — cate_err: 1.4257 — cate_nn_err: 2.7367 \n",
      "10/10 [==============================] - 1s 56ms/step - loss: 33.4020 - standard_loss: 27.2861 - regression_loss: 26.5908 - treatment_acc: 0.4868 - val_loss: 37.5612 - val_standard_loss: 29.5982 - val_regression_loss: 28.9015 - val_treatment_acc: 0.4683 - lr: 1.0000e-05\n",
      "Epoch 6/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 24.6772 - standard_loss: 19.9755 - regression_loss: 19.2826 - treatment_acc: 0.5312 — ate_err: 0.6594  — aipw_err: 1.5207 — cate_err: 1.2332 — cate_nn_err: 2.7322 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 30.2341 - standard_loss: 24.2213 - regression_loss: 23.5263 - treatment_acc: 0.4912 - val_loss: 34.5826 - val_standard_loss: 26.9393 - val_regression_loss: 26.2434 - val_treatment_acc: 0.4938 - lr: 1.0000e-05\n",
      "Epoch 7/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 30.2113 - standard_loss: 25.5090 - regression_loss: 24.8157 - treatment_acc: 0.6094 — ate_err: 0.5102  — aipw_err: 1.3103 — cate_err: 1.1447 — cate_nn_err: 2.7404 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 27.0334 - standard_loss: 22.1517 - regression_loss: 21.4581 - treatment_acc: 0.5039 - val_loss: 32.4238 - val_standard_loss: 24.9996 - val_regression_loss: 24.3046 - val_treatment_acc: 0.4938 - lr: 1.0000e-05\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - ETA: 0s - loss: 26.5957 - standard_loss: 20.8274 - regression_loss: 20.1345 - treatment_acc: 0.5022 — ate_err: 0.3721  — aipw_err: 1.1772 — cate_err: 1.0850 — cate_nn_err: 2.7817 \n",
      "10/10 [==============================] - 0s 43ms/step - loss: 26.5957 - standard_loss: 20.8274 - regression_loss: 20.1345 - treatment_acc: 0.5022 - val_loss: 30.8383 - val_standard_loss: 23.6008 - val_regression_loss: 22.9071 - val_treatment_acc: 0.5294 - lr: 1.0000e-05\n",
      "Epoch 9/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 34.2871 - standard_loss: 29.5841 - regression_loss: 28.8934 - treatment_acc: 0.5469 — ate_err: 0.3535  — aipw_err: 1.1486 — cate_err: 1.0717 — cate_nn_err: 2.8123 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 25.4427 - standard_loss: 19.7843 - regression_loss: 19.0924 - treatment_acc: 0.5163 - val_loss: 29.6687 - val_standard_loss: 22.5354 - val_regression_loss: 21.8426 - val_treatment_acc: 0.5346 - lr: 1.0000e-05\n",
      "Epoch 10/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 23.6675 - standard_loss: 18.9643 - regression_loss: 18.2642 - treatment_acc: 0.3906 — ate_err: 0.3202  — aipw_err: 1.1109 — cate_err: 1.0540 — cate_nn_err: 2.8446 \n",
      "10/10 [==============================] - 0s 43ms/step - loss: 24.6092 - standard_loss: 19.0535 - regression_loss: 18.3635 - treatment_acc: 0.5432 - val_loss: 28.7963 - val_standard_loss: 21.7569 - val_regression_loss: 21.0654 - val_treatment_acc: 0.5398 - lr: 1.0000e-05\n",
      "Epoch 11/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 30.6710 - standard_loss: 25.9676 - regression_loss: 25.2723 - treatment_acc: 0.4375 — ate_err: 0.2484  — aipw_err: 1.0504 — cate_err: 1.0249 — cate_nn_err: 2.8641 \n",
      "10/10 [==============================] - 0s 39ms/step - loss: 23.9703 - standard_loss: 18.4319 - regression_loss: 17.7430 - treatment_acc: 0.5368 - val_loss: 28.0491 - val_standard_loss: 21.1200 - val_regression_loss: 20.4300 - val_treatment_acc: 0.5554 - lr: 1.0000e-05\n",
      "Epoch 12/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.0036 - standard_loss: 14.3001 - regression_loss: 13.6144 - treatment_acc: 0.5156 — ate_err: 0.3044  — aipw_err: 1.0454 — cate_err: 1.0224 — cate_nn_err: 2.8787 \n",
      "10/10 [==============================] - 0s 36ms/step - loss: 23.4109 - standard_loss: 17.8372 - regression_loss: 17.1498 - treatment_acc: 0.5651 - val_loss: 27.5388 - val_standard_loss: 20.6312 - val_regression_loss: 19.9422 - val_treatment_acc: 0.5502 - lr: 1.0000e-05\n",
      "Epoch 13/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 26.8999 - standard_loss: 22.1965 - regression_loss: 21.5031 - treatment_acc: 0.5469 — ate_err: 0.2813  — aipw_err: 0.9860 — cate_err: 0.9930 — cate_nn_err: 2.8739 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 22.7684 - standard_loss: 17.3827 - regression_loss: 16.6952 - treatment_acc: 0.5696 - val_loss: 27.0570 - val_standard_loss: 20.2107 - val_regression_loss: 19.5229 - val_treatment_acc: 0.5658 - lr: 1.0000e-05\n",
      "Epoch 14/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.4299 - standard_loss: 14.7265 - regression_loss: 14.0402 - treatment_acc: 0.5781 — ate_err: 0.2632  — aipw_err: 0.9403 — cate_err: 0.9697 — cate_nn_err: 2.8693 \n",
      "10/10 [==============================] - 0s 42ms/step - loss: 22.5927 - standard_loss: 16.9578 - regression_loss: 16.2720 - treatment_acc: 0.5712 - val_loss: 26.5737 - val_standard_loss: 19.7849 - val_regression_loss: 19.0984 - val_treatment_acc: 0.5961 - lr: 1.0000e-05\n",
      "Epoch 15/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 22.2997 - standard_loss: 17.5964 - regression_loss: 16.9173 - treatment_acc: 0.5625 — ate_err: 0.2677  — aipw_err: 0.9078 — cate_err: 0.9528 — cate_nn_err: 2.8632 \n",
      "10/10 [==============================] - 0s 33ms/step - loss: 21.8480 - standard_loss: 16.5357 - regression_loss: 15.8518 - treatment_acc: 0.5932 - val_loss: 26.2068 - val_standard_loss: 19.4533 - val_regression_loss: 18.7680 - val_treatment_acc: 0.6013 - lr: 1.0000e-05\n",
      "Epoch 16/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 26.4483 - standard_loss: 21.7450 - regression_loss: 21.0561 - treatment_acc: 0.5781 — ate_err: 0.2425  — aipw_err: 0.8620 — cate_err: 0.9285 — cate_nn_err: 2.8525 \n",
      "10/10 [==============================] - 0s 43ms/step - loss: 21.5860 - standard_loss: 16.2026 - regression_loss: 15.5187 - treatment_acc: 0.6041 - val_loss: 25.8095 - val_standard_loss: 19.1178 - val_regression_loss: 18.4339 - val_treatment_acc: 0.6013 - lr: 1.0000e-05\n",
      "Epoch 17/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 23.0266 - standard_loss: 18.3233 - regression_loss: 17.6378 - treatment_acc: 0.6094 — ate_err: 0.2594  — aipw_err: 0.8438 — cate_err: 0.9186 — cate_nn_err: 2.8553 \n",
      "10/10 [==============================] - 0s 39ms/step - loss: 21.1116 - standard_loss: 15.8456 - regression_loss: 15.1626 - treatment_acc: 0.6088 - val_loss: 25.5170 - val_standard_loss: 18.8427 - val_regression_loss: 18.1600 - val_treatment_acc: 0.6321 - lr: 1.0000e-05\n",
      "Epoch 18/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.5696 - standard_loss: 14.8663 - regression_loss: 14.1771 - treatment_acc: 0.5469 — ate_err: 0.2607  — aipw_err: 0.8217 — cate_err: 0.9065 — cate_nn_err: 2.8577 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 20.8480 - standard_loss: 15.5215 - regression_loss: 14.8409 - treatment_acc: 0.6340 - val_loss: 25.1838 - val_standard_loss: 18.5442 - val_regression_loss: 17.8627 - val_treatment_acc: 0.6529 - lr: 1.0000e-05\n",
      "Epoch 19/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.8614 - standard_loss: 12.1582 - regression_loss: 11.4762 - treatment_acc: 0.6250 — ate_err: 0.2820  — aipw_err: 0.7960 — cate_err: 0.8922 — cate_nn_err: 2.8499 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 20.7575 - standard_loss: 15.2170 - regression_loss: 14.5371 - treatment_acc: 0.6371 - val_loss: 24.9430 - val_standard_loss: 18.3164 - val_regression_loss: 17.6360 - val_treatment_acc: 0.6581 - lr: 1.0000e-05\n",
      "Epoch 20/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.3001 - standard_loss: 11.5969 - regression_loss: 10.9158 - treatment_acc: 0.6094 — ate_err: 0.2499  — aipw_err: 0.7510 — cate_err: 0.8666 — cate_nn_err: 2.8402 \n",
      "10/10 [==============================] - 0s 33ms/step - loss: 20.4577 - standard_loss: 14.9656 - regression_loss: 14.2868 - treatment_acc: 0.6338 - val_loss: 24.6834 - val_standard_loss: 18.0858 - val_regression_loss: 17.4066 - val_treatment_acc: 0.6634 - lr: 1.0000e-05\n",
      "Epoch 21/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.6536 - standard_loss: 13.9504 - regression_loss: 13.2685 - treatment_acc: 0.5625 — ate_err: 0.2281  — aipw_err: 0.7235 — cate_err: 0.8506 — cate_nn_err: 2.8416 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 20.0414 - standard_loss: 14.7511 - regression_loss: 14.0735 - treatment_acc: 0.6574 - val_loss: 24.4552 - val_standard_loss: 17.8862 - val_regression_loss: 17.2083 - val_treatment_acc: 0.6634 - lr: 1.0000e-05\n",
      "Epoch 22/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 20.7557 - standard_loss: 16.0526 - regression_loss: 15.3780 - treatment_acc: 0.7344 — ate_err: 0.2846  — aipw_err: 0.7378 — cate_err: 0.8590 — cate_nn_err: 2.8462 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 19.8049 - standard_loss: 14.5576 - regression_loss: 13.8803 - treatment_acc: 0.6556 - val_loss: 24.2882 - val_standard_loss: 17.7191 - val_regression_loss: 17.0422 - val_treatment_acc: 0.6634 - lr: 1.0000e-05\n",
      "Epoch 23/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 23.0903 - standard_loss: 18.3872 - regression_loss: 17.7013 - treatment_acc: 0.6250 — ate_err: 0.2849  — aipw_err: 0.7205 — cate_err: 0.8488 — cate_nn_err: 2.8413 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 19.7510 - standard_loss: 14.3373 - regression_loss: 13.6616 - treatment_acc: 0.6714 - val_loss: 24.1096 - val_standard_loss: 17.5525 - val_regression_loss: 16.8767 - val_treatment_acc: 0.6686 - lr: 1.0000e-05\n",
      "Epoch 24/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.8627 - standard_loss: 14.1597 - regression_loss: 13.4755 - treatment_acc: 0.5469 — ate_err: 0.2301  — aipw_err: 0.6729 — cate_err: 0.8203 — cate_nn_err: 2.8379 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 19.4061 - standard_loss: 14.1499 - regression_loss: 13.4741 - treatment_acc: 0.6696 - val_loss: 23.9671 - val_standard_loss: 17.4363 - val_regression_loss: 16.7618 - val_treatment_acc: 0.6790 - lr: 1.0000e-05\n",
      "Epoch 25/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.7021 - standard_loss: 14.9992 - regression_loss: 14.3240 - treatment_acc: 0.7344 — ate_err: 0.2253  — aipw_err: 0.6616 — cate_err: 0.8134 — cate_nn_err: 2.8466 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 19.0787 - standard_loss: 14.0031 - regression_loss: 13.3307 - treatment_acc: 0.7077 - val_loss: 23.7889 - val_standard_loss: 17.2895 - val_regression_loss: 16.6162 - val_treatment_acc: 0.7045 - lr: 1.0000e-05\n",
      "Epoch 26/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 20.2118 - standard_loss: 15.5089 - regression_loss: 14.8328 - treatment_acc: 0.6562 — ate_err: 0.2682  — aipw_err: 0.6719 — cate_err: 0.8197 — cate_nn_err: 2.8547 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 19.2587 - standard_loss: 13.8459 - regression_loss: 13.1740 - treatment_acc: 0.6981 - val_loss: 23.6559 - val_standard_loss: 17.1459 - val_regression_loss: 16.4734 - val_treatment_acc: 0.7045 - lr: 1.0000e-05\n",
      "Epoch 27/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.2366 - standard_loss: 12.5337 - regression_loss: 11.8498 - treatment_acc: 0.6406 — ate_err: 0.2378  — aipw_err: 0.6427 — cate_err: 0.8017 — cate_nn_err: 2.8553 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 18.9475 - standard_loss: 13.7157 - regression_loss: 13.0430 - treatment_acc: 0.6996 - val_loss: 23.4994 - val_standard_loss: 17.0063 - val_regression_loss: 16.3350 - val_treatment_acc: 0.7050 - lr: 1.0000e-05\n",
      "Epoch 28/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.3500 - standard_loss: 11.6472 - regression_loss: 10.9704 - treatment_acc: 0.7188 — ate_err: 0.2517  — aipw_err: 0.6415 — cate_err: 0.8009 — cate_nn_err: 2.8540 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 19.0813 - standard_loss: 13.6646 - regression_loss: 12.9926 - treatment_acc: 0.6978 - val_loss: 23.4289 - val_standard_loss: 16.9428 - val_regression_loss: 16.2726 - val_treatment_acc: 0.7154 - lr: 1.0000e-05\n",
      "Epoch 29/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 23.8585 - standard_loss: 19.1558 - regression_loss: 18.4899 - treatment_acc: 0.7344 — ate_err: 0.2511  — aipw_err: 0.6399 — cate_err: 0.8000 — cate_nn_err: 2.8512 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 18.9161 - standard_loss: 13.5266 - regression_loss: 12.8563 - treatment_acc: 0.7057 - val_loss: 23.3431 - val_standard_loss: 16.8714 - val_regression_loss: 16.2022 - val_treatment_acc: 0.7259 - lr: 1.0000e-05\n",
      "Epoch 30/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.2897 - standard_loss: 14.5871 - regression_loss: 13.9241 - treatment_acc: 0.7188 — ate_err: 0.2313  — aipw_err: 0.6208 — cate_err: 0.7879 — cate_nn_err: 2.8541 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 18.8665 - standard_loss: 13.4165 - regression_loss: 12.7470 - treatment_acc: 0.7104 - val_loss: 23.2070 - val_standard_loss: 16.7452 - val_regression_loss: 16.0770 - val_treatment_acc: 0.7363 - lr: 1.0000e-05\n",
      "Epoch 31/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 23.7264 - standard_loss: 19.0238 - regression_loss: 18.3651 - treatment_acc: 0.7812 — ate_err: 0.2086  — aipw_err: 0.6034 — cate_err: 0.7768 — cate_nn_err: 2.8575 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 18.6896 - standard_loss: 13.3326 - regression_loss: 12.6645 - treatment_acc: 0.7324 - val_loss: 23.0841 - val_standard_loss: 16.6320 - val_regression_loss: 15.9649 - val_treatment_acc: 0.7467 - lr: 1.0000e-05\n",
      "Epoch 32/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.6391 - standard_loss: 13.9366 - regression_loss: 13.2561 - treatment_acc: 0.5938 — ate_err: 0.2100  — aipw_err: 0.5968 — cate_err: 0.7725 — cate_nn_err: 2.8496 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 18.5611 - standard_loss: 13.2408 - regression_loss: 12.5734 - treatment_acc: 0.7292 - val_loss: 23.1035 - val_standard_loss: 16.6514 - val_regression_loss: 15.9853 - val_treatment_acc: 0.7519 - lr: 1.0000e-05\n",
      "Epoch 33/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 21.9963 - standard_loss: 17.2940 - regression_loss: 16.6179 - treatment_acc: 0.6250 — ate_err: 0.2069  — aipw_err: 0.5890 — cate_err: 0.7675 — cate_nn_err: 2.8465 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 18.5759 - standard_loss: 13.2060 - regression_loss: 12.5397 - treatment_acc: 0.7356 - val_loss: 22.9805 - val_standard_loss: 16.5374 - val_regression_loss: 15.8722 - val_treatment_acc: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 34/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 20.6616 - standard_loss: 15.9593 - regression_loss: 15.2911 - treatment_acc: 0.6875 — ate_err: 0.2068  — aipw_err: 0.5870 — cate_err: 0.7662 — cate_nn_err: 2.8480 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 18.3440 - standard_loss: 13.0804 - regression_loss: 12.4155 - treatment_acc: 0.7435 - val_loss: 22.9419 - val_standard_loss: 16.4967 - val_regression_loss: 15.8324 - val_treatment_acc: 0.7931 - lr: 1.0000e-05\n",
      "Epoch 35/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.0094 - standard_loss: 14.3073 - regression_loss: 13.6301 - treatment_acc: 0.7188 — ate_err: 0.2028  — aipw_err: 0.5779 — cate_err: 0.7602 — cate_nn_err: 2.8481 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 18.3103 - standard_loss: 13.0153 - regression_loss: 12.3505 - treatment_acc: 0.7465 - val_loss: 22.8337 - val_standard_loss: 16.4029 - val_regression_loss: 15.7396 - val_treatment_acc: 0.7931 - lr: 1.0000e-05\n",
      "Epoch 36/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.5975 - standard_loss: 14.8955 - regression_loss: 14.2296 - treatment_acc: 0.7500 — ate_err: 0.2434  — aipw_err: 0.5816 — cate_err: 0.7626 — cate_nn_err: 2.8412 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 18.2226 - standard_loss: 13.0123 - regression_loss: 12.3501 - treatment_acc: 0.7592 - val_loss: 22.7563 - val_standard_loss: 16.3178 - val_regression_loss: 15.6553 - val_treatment_acc: 0.7931 - lr: 1.0000e-05\n",
      "Epoch 37/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.5102 - standard_loss: 14.8083 - regression_loss: 14.1544 - treatment_acc: 0.8125 — ate_err: 0.2441  — aipw_err: 0.5830 — cate_err: 0.7635 — cate_nn_err: 2.8396 \n",
      "10/10 [==============================] - 0s 36ms/step - loss: 18.1848 - standard_loss: 12.9066 - regression_loss: 12.2427 - treatment_acc: 0.7527 - val_loss: 22.7362 - val_standard_loss: 16.3045 - val_regression_loss: 15.6430 - val_treatment_acc: 0.7983 - lr: 1.0000e-05\n",
      "Epoch 38/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.8937 - standard_loss: 14.1919 - regression_loss: 13.5353 - treatment_acc: 0.7969 — ate_err: 0.2254  — aipw_err: 0.5772 — cate_err: 0.7597 — cate_nn_err: 2.8510 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 18.1874 - standard_loss: 12.8737 - regression_loss: 12.2110 - treatment_acc: 0.7478 - val_loss: 22.6677 - val_standard_loss: 16.2565 - val_regression_loss: 15.5960 - val_treatment_acc: 0.8187 - lr: 1.0000e-05\n",
      "Epoch 39/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.0944 - standard_loss: 14.3928 - regression_loss: 13.7432 - treatment_acc: 0.8438 — ate_err: 0.2218  — aipw_err: 0.5672 — cate_err: 0.7531 — cate_nn_err: 2.8503 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 18.1503 - standard_loss: 12.8136 - regression_loss: 12.1527 - treatment_acc: 0.7653 - val_loss: 22.5793 - val_standard_loss: 16.1690 - val_regression_loss: 15.5094 - val_treatment_acc: 0.8390 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.2756 - standard_loss: 13.5740 - regression_loss: 12.9131 - treatment_acc: 0.7656 — ate_err: 0.2192  — aipw_err: 0.5692 — cate_err: 0.7545 — cate_nn_err: 2.8590 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 18.1384 - standard_loss: 12.8078 - regression_loss: 12.1474 - treatment_acc: 0.7557 - val_loss: 22.5375 - val_standard_loss: 16.1319 - val_regression_loss: 15.4731 - val_treatment_acc: 0.8390 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.6626 - standard_loss: 11.9611 - regression_loss: 11.3175 - treatment_acc: 0.8438 — ate_err: 0.2299  — aipw_err: 0.5605 — cate_err: 0.7486 — cate_nn_err: 2.8548 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 18.1290 - standard_loss: 12.7461 - regression_loss: 12.0857 - treatment_acc: 0.7604 - val_loss: 22.4779 - val_standard_loss: 16.0722 - val_regression_loss: 15.4144 - val_treatment_acc: 0.8390 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.0697 - standard_loss: 12.3684 - regression_loss: 11.7112 - treatment_acc: 0.7656 — ate_err: 0.2078  — aipw_err: 0.5417 — cate_err: 0.7360 — cate_nn_err: 2.8445 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 17.9344 - standard_loss: 12.7033 - regression_loss: 12.0416 - treatment_acc: 0.7523 - val_loss: 22.4417 - val_standard_loss: 16.0487 - val_regression_loss: 15.3918 - val_treatment_acc: 0.8390 - lr: 1.0000e-05\n",
      "Epoch 43/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.6009 - standard_loss: 14.8998 - regression_loss: 14.2480 - treatment_acc: 0.8438 — ate_err: 0.2104  — aipw_err: 0.5454 — cate_err: 0.7385 — cate_nn_err: 2.8578 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 17.7655 - standard_loss: 12.6579 - regression_loss: 11.9997 - treatment_acc: 0.7763 - val_loss: 22.3595 - val_standard_loss: 15.9688 - val_regression_loss: 15.3127 - val_treatment_acc: 0.8442 - lr: 1.0000e-05\n",
      "Epoch 44/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 21.8010 - standard_loss: 17.0999 - regression_loss: 16.4391 - treatment_acc: 0.8125 — ate_err: 0.1915  — aipw_err: 0.5358 — cate_err: 0.7320 — cate_nn_err: 2.8521 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 17.8577 - standard_loss: 12.6202 - regression_loss: 11.9635 - treatment_acc: 0.7888 - val_loss: 22.2834 - val_standard_loss: 15.9046 - val_regression_loss: 15.2494 - val_treatment_acc: 0.8442 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.4640 - standard_loss: 14.7631 - regression_loss: 14.0965 - treatment_acc: 0.7188 — ate_err: 0.2110  — aipw_err: 0.5453 — cate_err: 0.7384 — cate_nn_err: 2.8574 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 17.7008 - standard_loss: 12.5442 - regression_loss: 11.8869 - treatment_acc: 0.7856 - val_loss: 22.2497 - val_standard_loss: 15.8780 - val_regression_loss: 15.2236 - val_treatment_acc: 0.8442 - lr: 1.0000e-05\n",
      "Epoch 46/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 20.1706 - standard_loss: 15.4699 - regression_loss: 14.7927 - treatment_acc: 0.6875 — ate_err: 0.1899  — aipw_err: 0.5258 — cate_err: 0.7251 — cate_nn_err: 2.8437 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 17.8988 - standard_loss: 12.5792 - regression_loss: 11.9243 - treatment_acc: 0.7888 - val_loss: 22.2287 - val_standard_loss: 15.8708 - val_regression_loss: 15.2173 - val_treatment_acc: 0.8442 - lr: 1.0000e-05\n",
      "Epoch 47/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 20.8238 - standard_loss: 16.1232 - regression_loss: 15.4811 - treatment_acc: 0.8594 — ate_err: 0.1793  — aipw_err: 0.5171 — cate_err: 0.7191 — cate_nn_err: 2.8467 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 17.6752 - standard_loss: 12.4742 - regression_loss: 11.8205 - treatment_acc: 0.7983 - val_loss: 22.1790 - val_standard_loss: 15.8209 - val_regression_loss: 15.1683 - val_treatment_acc: 0.8494 - lr: 1.0000e-05\n",
      "Epoch 48/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.9992 - standard_loss: 10.2987 - regression_loss: 9.6408 - treatment_acc: 0.7656 — ate_err: 0.2317  — aipw_err: 0.5442 — cate_err: 0.7377 — cate_nn_err: 2.8581 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 17.6959 - standard_loss: 12.4560 - regression_loss: 11.8024 - treatment_acc: 0.8015 - val_loss: 22.1042 - val_standard_loss: 15.7462 - val_regression_loss: 15.0943 - val_treatment_acc: 0.8494 - lr: 1.0000e-05\n",
      "Epoch 49/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.2225 - standard_loss: 11.5222 - regression_loss: 10.8703 - treatment_acc: 0.7969 — ate_err: 0.1889  — aipw_err: 0.5149 — cate_err: 0.7176 — cate_nn_err: 2.8549 \n",
      "10/10 [==============================] - 0s 37ms/step - loss: 17.7575 - standard_loss: 12.4005 - regression_loss: 11.7463 - treatment_acc: 0.7934 - val_loss: 22.0061 - val_standard_loss: 15.6654 - val_regression_loss: 15.0144 - val_treatment_acc: 0.8343 - lr: 1.0000e-05\n",
      "Epoch 50/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 12.9337 - standard_loss: 8.2335 - regression_loss: 7.5727 - treatment_acc: 0.7656 — ate_err: 0.1926  — aipw_err: 0.5118 — cate_err: 0.7154 — cate_nn_err: 2.8524 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 17.8053 - standard_loss: 12.4115 - regression_loss: 11.7591 - treatment_acc: 0.7981 - val_loss: 21.9796 - val_standard_loss: 15.6398 - val_regression_loss: 14.9897 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 51/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.3392 - standard_loss: 10.6391 - regression_loss: 9.9896 - treatment_acc: 0.8281 — ate_err: 0.1794  — aipw_err: 0.5033 — cate_err: 0.7095 — cate_nn_err: 2.8489 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 17.7754 - standard_loss: 12.3954 - regression_loss: 11.7440 - treatment_acc: 0.8045 - val_loss: 21.9503 - val_standard_loss: 15.6176 - val_regression_loss: 14.9683 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 52/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.6820 - standard_loss: 14.9821 - regression_loss: 14.3197 - treatment_acc: 0.7188 — ate_err: 0.1901  — aipw_err: 0.5054 — cate_err: 0.7109 — cate_nn_err: 2.8487 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 17.4719 - standard_loss: 12.3036 - regression_loss: 11.6538 - treatment_acc: 0.8061 - val_loss: 21.8603 - val_standard_loss: 15.5393 - val_regression_loss: 14.8909 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 53/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.7081 - standard_loss: 12.0083 - regression_loss: 11.3555 - treatment_acc: 0.7812 — ate_err: 0.1887  — aipw_err: 0.5076 — cate_err: 0.7124 — cate_nn_err: 2.8470 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 17.5374 - standard_loss: 12.3114 - regression_loss: 11.6608 - treatment_acc: 0.7949 - val_loss: 21.7751 - val_standard_loss: 15.4723 - val_regression_loss: 14.8247 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 54/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.7785 - standard_loss: 11.0789 - regression_loss: 10.4180 - treatment_acc: 0.7500 — ate_err: 0.1594  — aipw_err: 0.4902 — cate_err: 0.7001 — cate_nn_err: 2.8442 \n",
      "10/10 [==============================] - 0s 36ms/step - loss: 17.5195 - standard_loss: 12.2875 - regression_loss: 11.6347 - treatment_acc: 0.7725 - val_loss: 21.7400 - val_standard_loss: 15.4399 - val_regression_loss: 14.7932 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 55/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.6305 - standard_loss: 10.9311 - regression_loss: 10.2699 - treatment_acc: 0.7500 — ate_err: 0.2154  — aipw_err: 0.5045 — cate_err: 0.7103 — cate_nn_err: 2.8432 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 17.5276 - standard_loss: 12.1876 - regression_loss: 11.5381 - treatment_acc: 0.7949 - val_loss: 21.7272 - val_standard_loss: 15.4189 - val_regression_loss: 14.7727 - val_treatment_acc: 0.8343 - lr: 1.0000e-05\n",
      "Epoch 56/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.3825 - standard_loss: 13.6832 - regression_loss: 13.0407 - treatment_acc: 0.8125 — ate_err: 0.1964  — aipw_err: 0.4998 — cate_err: 0.7070 — cate_nn_err: 2.8445 \n",
      "10/10 [==============================] - 0s 31ms/step - loss: 17.4097 - standard_loss: 12.2165 - regression_loss: 11.5665 - treatment_acc: 0.7885 - val_loss: 21.6834 - val_standard_loss: 15.3901 - val_regression_loss: 14.7448 - val_treatment_acc: 0.8343 - lr: 1.0000e-05\n",
      "Epoch 57/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.4487 - standard_loss: 11.7495 - regression_loss: 11.1115 - treatment_acc: 0.8594 — ate_err: 0.1616  — aipw_err: 0.4797 — cate_err: 0.6926 — cate_nn_err: 2.8354 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 17.4961 - standard_loss: 12.1917 - regression_loss: 11.5445 - treatment_acc: 0.8013 - val_loss: 21.6634 - val_standard_loss: 15.3747 - val_regression_loss: 14.7303 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 58/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.4596 - standard_loss: 9.7606 - regression_loss: 9.1152 - treatment_acc: 0.8125 — ate_err: 0.2133  — aipw_err: 0.4950 — cate_err: 0.7035 — cate_nn_err: 2.8346 \n",
      "10/10 [==============================] - 0s 37ms/step - loss: 17.3541 - standard_loss: 12.1873 - regression_loss: 11.5403 - treatment_acc: 0.8028 - val_loss: 21.5921 - val_standard_loss: 15.3059 - val_regression_loss: 14.6621 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 59/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.6140 - standard_loss: 9.9152 - regression_loss: 9.2598 - treatment_acc: 0.7656 — ate_err: 0.2084  — aipw_err: 0.4936 — cate_err: 0.7026 — cate_nn_err: 2.8426 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 17.2547 - standard_loss: 12.1567 - regression_loss: 11.5103 - treatment_acc: 0.8028 - val_loss: 21.5208 - val_standard_loss: 15.2399 - val_regression_loss: 14.5969 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 60/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.7736 - standard_loss: 12.0749 - regression_loss: 11.4239 - treatment_acc: 0.8125 — ate_err: 0.1949  — aipw_err: 0.4837 — cate_err: 0.6955 — cate_nn_err: 2.8431 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 17.4402 - standard_loss: 12.0656 - regression_loss: 11.4187 - treatment_acc: 0.7948 - val_loss: 21.4643 - val_standard_loss: 15.1943 - val_regression_loss: 14.5520 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 61/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.9194 - standard_loss: 14.2208 - regression_loss: 13.5791 - treatment_acc: 0.8281 — ate_err: 0.1626  — aipw_err: 0.4673 — cate_err: 0.6836 — cate_nn_err: 2.8360 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 17.2011 - standard_loss: 12.0403 - regression_loss: 11.3971 - treatment_acc: 0.8139 - val_loss: 21.4268 - val_standard_loss: 15.1621 - val_regression_loss: 14.5207 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 62/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.4417 - standard_loss: 10.7433 - regression_loss: 10.0965 - treatment_acc: 0.8281 — ate_err: 0.2251  — aipw_err: 0.4884 — cate_err: 0.6989 — cate_nn_err: 2.8302 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 17.2284 - standard_loss: 12.0310 - regression_loss: 11.3869 - treatment_acc: 0.8107 - val_loss: 21.4099 - val_standard_loss: 15.1443 - val_regression_loss: 14.5035 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 63/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.2408 - standard_loss: 9.5426 - regression_loss: 8.9009 - treatment_acc: 0.8125 — ate_err: 0.1871  — aipw_err: 0.4698 — cate_err: 0.6854 — cate_nn_err: 2.8337 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 17.4119 - standard_loss: 12.0856 - regression_loss: 11.4416 - treatment_acc: 0.8091 - val_loss: 21.3467 - val_standard_loss: 15.0973 - val_regression_loss: 14.4574 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 64/300\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 17.4104 - standard_loss: 12.7123 - regression_loss: 12.0705 - treatment_acc: 0.8160 — ate_err: 0.2331  — aipw_err: 0.4836 — cate_err: 0.6954 — cate_nn_err: 2.8392 \n",
      "10/10 [==============================] - 0s 36ms/step - loss: 17.1516 - standard_loss: 11.9765 - regression_loss: 11.3317 - treatment_acc: 0.7963 - val_loss: 21.3074 - val_standard_loss: 15.0554 - val_regression_loss: 14.4161 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 65/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 20.8969 - standard_loss: 16.1989 - regression_loss: 15.5609 - treatment_acc: 0.8750 — ate_err: 0.1646  — aipw_err: 0.4545 — cate_err: 0.6741 — cate_nn_err: 2.8347 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 17.1158 - standard_loss: 11.9877 - regression_loss: 11.3444 - treatment_acc: 0.8027 - val_loss: 21.2457 - val_standard_loss: 15.0124 - val_regression_loss: 14.3739 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 66/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 20.9491 - standard_loss: 16.2513 - regression_loss: 15.6197 - treatment_acc: 0.8594 — ate_err: 0.2287  — aipw_err: 0.4835 — cate_err: 0.6953 — cate_nn_err: 2.8499 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 17.0449 - standard_loss: 11.9253 - regression_loss: 11.2841 - treatment_acc: 0.8091 - val_loss: 21.1453 - val_standard_loss: 14.9163 - val_regression_loss: 14.2784 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 67/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.1426 - standard_loss: 11.4449 - regression_loss: 10.8073 - treatment_acc: 0.8594 — ate_err: 0.1886  — aipw_err: 0.4548 — cate_err: 0.6744 — cate_nn_err: 2.8320 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 17.2156 - standard_loss: 11.9182 - regression_loss: 11.2772 - treatment_acc: 0.8059 - val_loss: 21.1694 - val_standard_loss: 14.9409 - val_regression_loss: 14.3039 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 68/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.5151 - standard_loss: 10.8176 - regression_loss: 10.1773 - treatment_acc: 0.8125 — ate_err: 0.1715  — aipw_err: 0.4526 — cate_err: 0.6727 — cate_nn_err: 2.8314 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 17.0179 - standard_loss: 11.8951 - regression_loss: 11.2547 - treatment_acc: 0.8059 - val_loss: 21.1487 - val_standard_loss: 14.9258 - val_regression_loss: 14.2895 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 69/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.6571 - standard_loss: 11.9597 - regression_loss: 11.3155 - treatment_acc: 0.8125 — ate_err: 0.1861  — aipw_err: 0.4525 — cate_err: 0.6727 — cate_nn_err: 2.8313 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 17.0549 - standard_loss: 11.8642 - regression_loss: 11.2250 - treatment_acc: 0.8106 - val_loss: 21.0667 - val_standard_loss: 14.8523 - val_regression_loss: 14.2167 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 70/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.3915 - standard_loss: 13.6942 - regression_loss: 13.0461 - treatment_acc: 0.7500 — ate_err: 0.1687  — aipw_err: 0.4417 — cate_err: 0.6646 — cate_nn_err: 2.8257 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 17.0541 - standard_loss: 11.8789 - regression_loss: 11.2397 - treatment_acc: 0.8042 - val_loss: 21.0420 - val_standard_loss: 14.8330 - val_regression_loss: 14.1982 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 71/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.5409 - standard_loss: 11.8438 - regression_loss: 11.2064 - treatment_acc: 0.8125 — ate_err: 0.1834  — aipw_err: 0.4416 — cate_err: 0.6645 — cate_nn_err: 2.8333 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 17.0469 - standard_loss: 11.7875 - regression_loss: 11.1486 - treatment_acc: 0.8074 - val_loss: 20.9616 - val_standard_loss: 14.7574 - val_regression_loss: 14.1233 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 72/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.2453 - standard_loss: 10.5484 - regression_loss: 9.8972 - treatment_acc: 0.7344 — ate_err: 0.1882  — aipw_err: 0.4390 — cate_err: 0.6626 — cate_nn_err: 2.8256 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.9187 - standard_loss: 11.7867 - regression_loss: 11.1468 - treatment_acc: 0.7994 - val_loss: 20.9126 - val_standard_loss: 14.7097 - val_regression_loss: 14.0762 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 73/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.6187 - standard_loss: 13.9219 - regression_loss: 13.2732 - treatment_acc: 0.7656 — ate_err: 0.1969  — aipw_err: 0.4445 — cate_err: 0.6667 — cate_nn_err: 2.8306 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.9402 - standard_loss: 11.7512 - regression_loss: 11.1140 - treatment_acc: 0.8154 - val_loss: 20.8594 - val_standard_loss: 14.6615 - val_regression_loss: 14.0287 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 74/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.3438 - standard_loss: 13.6471 - regression_loss: 13.0182 - treatment_acc: 0.8594 — ate_err: 0.1827  — aipw_err: 0.4385 — cate_err: 0.6622 — cate_nn_err: 2.8241 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.9579 - standard_loss: 11.7222 - regression_loss: 11.0842 - treatment_acc: 0.8058 - val_loss: 20.8590 - val_standard_loss: 14.6705 - val_regression_loss: 14.0385 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - ETA: 0s - loss: 16.9132 - standard_loss: 11.7481 - regression_loss: 11.1135 - treatment_acc: 0.8186 — ate_err: 0.2102  — aipw_err: 0.4440 — cate_err: 0.6663 — cate_nn_err: 2.8232 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 16.9132 - standard_loss: 11.7481 - regression_loss: 11.1135 - treatment_acc: 0.8186 - val_loss: 20.8016 - val_standard_loss: 14.6163 - val_regression_loss: 13.9849 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 76/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.4706 - standard_loss: 13.7742 - regression_loss: 13.1585 - treatment_acc: 0.9062 — ate_err: 0.2061  — aipw_err: 0.4452 — cate_err: 0.6672 — cate_nn_err: 2.8262 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.7852 - standard_loss: 11.6841 - regression_loss: 11.0496 - treatment_acc: 0.8154 - val_loss: 20.7911 - val_standard_loss: 14.6100 - val_regression_loss: 13.9794 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 77/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.2934 - standard_loss: 10.5971 - regression_loss: 9.9480 - treatment_acc: 0.7500 — ate_err: 0.1870  — aipw_err: 0.4311 — cate_err: 0.6566 — cate_nn_err: 2.8221 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 17.0141 - standard_loss: 11.6763 - regression_loss: 11.0403 - treatment_acc: 0.8058 - val_loss: 20.7701 - val_standard_loss: 14.5870 - val_regression_loss: 13.9571 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 78/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.0148 - standard_loss: 12.3187 - regression_loss: 11.6800 - treatment_acc: 0.8125 — ate_err: 0.2124  — aipw_err: 0.4335 — cate_err: 0.6584 — cate_nn_err: 2.8194 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.7249 - standard_loss: 11.6304 - regression_loss: 10.9967 - treatment_acc: 0.8122 - val_loss: 20.7199 - val_standard_loss: 14.5436 - val_regression_loss: 13.9143 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 79/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.1206 - standard_loss: 10.4246 - regression_loss: 9.7900 - treatment_acc: 0.8281 — ate_err: 0.1557  — aipw_err: 0.4140 — cate_err: 0.6434 — cate_nn_err: 2.8161 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.8841 - standard_loss: 11.6425 - regression_loss: 11.0080 - treatment_acc: 0.8058 - val_loss: 20.6733 - val_standard_loss: 14.5121 - val_regression_loss: 13.8836 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 80/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.0375 - standard_loss: 12.3417 - regression_loss: 11.6822 - treatment_acc: 0.6875 — ate_err: 0.1666  — aipw_err: 0.4162 — cate_err: 0.6451 — cate_nn_err: 2.8187 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.6544 - standard_loss: 11.5836 - regression_loss: 10.9495 - treatment_acc: 0.8058 - val_loss: 20.6227 - val_standard_loss: 14.4635 - val_regression_loss: 13.8357 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 81/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.1486 - standard_loss: 10.4529 - regression_loss: 9.8111 - treatment_acc: 0.7656 — ate_err: 0.1984  — aipw_err: 0.4238 — cate_err: 0.6510 — cate_nn_err: 2.8257 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.7884 - standard_loss: 11.5620 - regression_loss: 10.9316 - treatment_acc: 0.8186 - val_loss: 20.5296 - val_standard_loss: 14.3779 - val_regression_loss: 13.7507 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 82/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.5427 - standard_loss: 12.8471 - regression_loss: 12.2070 - treatment_acc: 0.7812 — ate_err: 0.1664  — aipw_err: 0.4096 — cate_err: 0.6400 — cate_nn_err: 2.8170 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.5339 - standard_loss: 11.5489 - regression_loss: 10.9166 - treatment_acc: 0.8058 - val_loss: 20.5251 - val_standard_loss: 14.3842 - val_regression_loss: 13.7577 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 83/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.2256 - standard_loss: 11.5303 - regression_loss: 10.8919 - treatment_acc: 0.7969 — ate_err: 0.1925  — aipw_err: 0.4198 — cate_err: 0.6479 — cate_nn_err: 2.8185 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.7706 - standard_loss: 11.5149 - regression_loss: 10.8822 - treatment_acc: 0.8058 - val_loss: 20.4709 - val_standard_loss: 14.3310 - val_regression_loss: 13.7051 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 84/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.3276 - standard_loss: 8.6324 - regression_loss: 8.0148 - treatment_acc: 0.8438 — ate_err: 0.1799  — aipw_err: 0.4109 — cate_err: 0.6410 — cate_nn_err: 2.8126 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.6816 - standard_loss: 11.5109 - regression_loss: 10.8802 - treatment_acc: 0.8090 - val_loss: 20.4678 - val_standard_loss: 14.3342 - val_regression_loss: 13.7090 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 85/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.3875 - standard_loss: 10.6924 - regression_loss: 10.0645 - treatment_acc: 0.8125 — ate_err: 0.1527  — aipw_err: 0.3998 — cate_err: 0.6323 — cate_nn_err: 2.8139 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.7396 - standard_loss: 11.5200 - regression_loss: 10.8901 - treatment_acc: 0.8090 - val_loss: 20.4211 - val_standard_loss: 14.2936 - val_regression_loss: 13.6692 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 86/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 21.9388 - standard_loss: 17.2439 - regression_loss: 16.6014 - treatment_acc: 0.7656 — ate_err: 0.1389  — aipw_err: 0.3932 — cate_err: 0.6271 — cate_nn_err: 2.8039 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.7618 - standard_loss: 11.4565 - regression_loss: 10.8278 - treatment_acc: 0.8154 - val_loss: 20.3724 - val_standard_loss: 14.2479 - val_regression_loss: 13.6241 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 87/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.8743 - standard_loss: 14.1794 - regression_loss: 13.5541 - treatment_acc: 0.8281\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      " — ate_err: 0.1449  — aipw_err: 0.3890 — cate_err: 0.6237 — cate_nn_err: 2.8006 \n",
      "10/10 [==============================] - 0s 33ms/step - loss: 16.7212 - standard_loss: 11.4886 - regression_loss: 10.8606 - treatment_acc: 0.8122 - val_loss: 20.3475 - val_standard_loss: 14.2214 - val_regression_loss: 13.5983 - val_treatment_acc: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 88/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.1331 - standard_loss: 13.4385 - regression_loss: 12.8202 - treatment_acc: 0.8438 — ate_err: 0.1827  — aipw_err: 0.4030 — cate_err: 0.6348 — cate_nn_err: 2.8088 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.6921 - standard_loss: 11.4022 - regression_loss: 10.7732 - treatment_acc: 0.8090 - val_loss: 20.2737 - val_standard_loss: 14.1539 - val_regression_loss: 13.5312 - val_treatment_acc: 0.8395 - lr: 5.0000e-06\n",
      "Epoch 89/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.7889 - standard_loss: 15.0943 - regression_loss: 14.4656 - treatment_acc: 0.8125 — ate_err: 0.1717  — aipw_err: 0.3973 — cate_err: 0.6303 — cate_nn_err: 2.8072 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.6068 - standard_loss: 11.3861 - regression_loss: 10.7600 - treatment_acc: 0.8186 - val_loss: 20.2522 - val_standard_loss: 14.1378 - val_regression_loss: 13.5155 - val_treatment_acc: 0.8395 - lr: 5.0000e-06\n",
      "Epoch 90/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.7854 - standard_loss: 10.0910 - regression_loss: 9.4361 - treatment_acc: 0.7031 — ate_err: 0.1718  — aipw_err: 0.3959 — cate_err: 0.6292 — cate_nn_err: 2.8087 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.4718 - standard_loss: 11.3884 - regression_loss: 10.7643 - treatment_acc: 0.8218 - val_loss: 20.2509 - val_standard_loss: 14.1371 - val_regression_loss: 13.5152 - val_treatment_acc: 0.8395 - lr: 5.0000e-06\n",
      "Epoch 91/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.2637 - standard_loss: 12.5693 - regression_loss: 11.9458 - treatment_acc: 0.7969 — ate_err: 0.1835  — aipw_err: 0.3997 — cate_err: 0.6322 — cate_nn_err: 2.8072 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.5604 - standard_loss: 11.3758 - regression_loss: 10.7470 - treatment_acc: 0.8058 - val_loss: 20.2327 - val_standard_loss: 14.1223 - val_regression_loss: 13.5006 - val_treatment_acc: 0.8395 - lr: 5.0000e-06\n",
      "Epoch 92/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.2384 - standard_loss: 9.5441 - regression_loss: 8.9113 - treatment_acc: 0.7812 — ate_err: 0.1606  — aipw_err: 0.3918 — cate_err: 0.6259 — cate_nn_err: 2.8117 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.4662 - standard_loss: 11.3649 - regression_loss: 10.7380 - treatment_acc: 0.8122 - val_loss: 20.2154 - val_standard_loss: 14.1085 - val_regression_loss: 13.4873 - val_treatment_acc: 0.8395 - lr: 5.0000e-06\n",
      "Epoch 93/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.4788 - standard_loss: 14.7845 - regression_loss: 14.1487 - treatment_acc: 0.7656 — ate_err: 0.1788  — aipw_err: 0.3968 — cate_err: 0.6299 — cate_nn_err: 2.8093 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.5066 - standard_loss: 11.3356 - regression_loss: 10.7090 - treatment_acc: 0.8122 - val_loss: 20.2132 - val_standard_loss: 14.1086 - val_regression_loss: 13.4877 - val_treatment_acc: 0.8395 - lr: 5.0000e-06\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - ETA: 0s - loss: 16.4848 - standard_loss: 11.3409 - regression_loss: 10.7161 - treatment_acc: 0.8154 — ate_err: 0.1673  — aipw_err: 0.3897 — cate_err: 0.6243 — cate_nn_err: 2.8072 \n",
      "10/10 [==============================] - 0s 41ms/step - loss: 16.4848 - standard_loss: 11.3409 - regression_loss: 10.7161 - treatment_acc: 0.8154 - val_loss: 20.2075 - val_standard_loss: 14.1022 - val_regression_loss: 13.4816 - val_treatment_acc: 0.8395 - lr: 5.0000e-06\n",
      "Epoch 95/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.6501 - standard_loss: 13.9560 - regression_loss: 13.2941 - treatment_acc: 0.6875 — ate_err: 0.1718  — aipw_err: 0.3921 — cate_err: 0.6262 — cate_nn_err: 2.8074 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.5843 - standard_loss: 11.3248 - regression_loss: 10.6983 - treatment_acc: 0.8090 - val_loss: 20.1956 - val_standard_loss: 14.0931 - val_regression_loss: 13.4728 - val_treatment_acc: 0.8395 - lr: 5.0000e-06\n",
      "Epoch 96/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.4087 - standard_loss: 11.7147 - regression_loss: 11.0767 - treatment_acc: 0.7656 — ate_err: 0.1833  — aipw_err: 0.3934 — cate_err: 0.6272 — cate_nn_err: 2.8105 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 16.4313 - standard_loss: 11.3207 - regression_loss: 10.6940 - treatment_acc: 0.8058 - val_loss: 20.1446 - val_standard_loss: 14.0437 - val_regression_loss: 13.4238 - val_treatment_acc: 0.8395 - lr: 5.0000e-06\n",
      "Epoch 97/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.5080 - standard_loss: 12.8140 - regression_loss: 12.1778 - treatment_acc: 0.7812 — ate_err: 0.1711  — aipw_err: 0.3893 — cate_err: 0.6239 — cate_nn_err: 2.8072 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.5574 - standard_loss: 11.3290 - regression_loss: 10.7037 - treatment_acc: 0.8090 - val_loss: 20.1537 - val_standard_loss: 14.0565 - val_regression_loss: 13.4369 - val_treatment_acc: 0.8395 - lr: 5.0000e-06\n",
      "Epoch 98/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.2315 - standard_loss: 9.5376 - regression_loss: 8.9036 - treatment_acc: 0.7812 — ate_err: 0.1781  — aipw_err: 0.3918 — cate_err: 0.6259 — cate_nn_err: 2.8114 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.4771 - standard_loss: 11.3141 - regression_loss: 10.6885 - treatment_acc: 0.8058 - val_loss: 20.0988 - val_standard_loss: 14.0063 - val_regression_loss: 13.3870 - val_treatment_acc: 0.8395 - lr: 5.0000e-06\n",
      "Epoch 99/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.1383 - standard_loss: 12.4445 - regression_loss: 11.7997 - treatment_acc: 0.7188 — ate_err: 0.2139  — aipw_err: 0.4032 — cate_err: 0.6350 — cate_nn_err: 2.7962 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.5456 - standard_loss: 11.3272 - regression_loss: 10.7028 - treatment_acc: 0.8122 - val_loss: 20.0944 - val_standard_loss: 13.9998 - val_regression_loss: 13.3807 - val_treatment_acc: 0.8395 - lr: 5.0000e-06\n",
      "Epoch 100/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 20.1183 - standard_loss: 15.4246 - regression_loss: 14.8223 - treatment_acc: 0.8750 — ate_err: 0.1410  — aipw_err: 0.3769 — cate_err: 0.6139 — cate_nn_err: 2.7905 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.5354 - standard_loss: 11.2897 - regression_loss: 10.6667 - treatment_acc: 0.8186 - val_loss: 20.1056 - val_standard_loss: 14.0179 - val_regression_loss: 13.3992 - val_treatment_acc: 0.8395 - lr: 5.0000e-06\n",
      "Epoch 101/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.3397 - standard_loss: 12.6460 - regression_loss: 12.0282 - treatment_acc: 0.8281\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      " — ate_err: 0.1775  — aipw_err: 0.3866 — cate_err: 0.6218 — cate_nn_err: 2.7925 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.4327 - standard_loss: 11.2933 - regression_loss: 10.6688 - treatment_acc: 0.8090 - val_loss: 20.0651 - val_standard_loss: 13.9804 - val_regression_loss: 13.3620 - val_treatment_acc: 0.8395 - lr: 5.0000e-06\n",
      "Epoch 102/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 12.9509 - standard_loss: 8.2573 - regression_loss: 7.6525 - treatment_acc: 0.8906 — ate_err: 0.1848  — aipw_err: 0.3889 — cate_err: 0.6236 — cate_nn_err: 2.7902 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.4565 - standard_loss: 11.2443 - regression_loss: 10.6195 - treatment_acc: 0.8090 - val_loss: 20.0563 - val_standard_loss: 13.9705 - val_regression_loss: 13.3524 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 103/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.5957 - standard_loss: 11.9022 - regression_loss: 11.2862 - treatment_acc: 0.8438 — ate_err: 0.1765  — aipw_err: 0.3850 — cate_err: 0.6205 — cate_nn_err: 2.7902 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 16.4114 - standard_loss: 11.2426 - regression_loss: 10.6211 - treatment_acc: 0.8186 - val_loss: 20.0435 - val_standard_loss: 13.9585 - val_regression_loss: 13.3406 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 104/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 20.0620 - standard_loss: 15.3684 - regression_loss: 14.7377 - treatment_acc: 0.7812 — ate_err: 0.1764  — aipw_err: 0.3845 — cate_err: 0.6201 — cate_nn_err: 2.7916 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.4609 - standard_loss: 11.2336 - regression_loss: 10.6106 - treatment_acc: 0.8122 - val_loss: 20.0250 - val_standard_loss: 13.9425 - val_regression_loss: 13.3247 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 105/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.7617 - standard_loss: 12.0683 - regression_loss: 11.4247 - treatment_acc: 0.7500 — ate_err: 0.1710  — aipw_err: 0.3811 — cate_err: 0.6173 — cate_nn_err: 2.7912 \n",
      "10/10 [==============================] - 0s 26ms/step - loss: 16.4482 - standard_loss: 11.2294 - regression_loss: 10.6052 - treatment_acc: 0.8090 - val_loss: 20.0193 - val_standard_loss: 13.9368 - val_regression_loss: 13.3192 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 106/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.3609 - standard_loss: 14.6674 - regression_loss: 14.0408 - treatment_acc: 0.7812 — ate_err: 0.1625  — aipw_err: 0.3774 — cate_err: 0.6144 — cate_nn_err: 2.7934 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.1756 - standard_loss: 11.2284 - regression_loss: 10.6057 - treatment_acc: 0.8122 - val_loss: 20.0129 - val_standard_loss: 13.9312 - val_regression_loss: 13.3137 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 107/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.0675 - standard_loss: 12.3741 - regression_loss: 11.7472 - treatment_acc: 0.7969 — ate_err: 0.1642  — aipw_err: 0.3774 — cate_err: 0.6143 — cate_nn_err: 2.7908 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.4008 - standard_loss: 11.2244 - regression_loss: 10.6023 - treatment_acc: 0.8154 - val_loss: 19.9976 - val_standard_loss: 13.9177 - val_regression_loss: 13.3004 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 108/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.7867 - standard_loss: 11.0933 - regression_loss: 10.4637 - treatment_acc: 0.7812 — ate_err: 0.1882  — aipw_err: 0.3853 — cate_err: 0.6207 — cate_nn_err: 2.7958 \n",
      "10/10 [==============================] - 0s 49ms/step - loss: 16.3757 - standard_loss: 11.2454 - regression_loss: 10.6247 - treatment_acc: 0.8186 - val_loss: 19.9917 - val_standard_loss: 13.9106 - val_regression_loss: 13.2935 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 109/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.6846 - standard_loss: 10.9912 - regression_loss: 10.3563 - treatment_acc: 0.7656 — ate_err: 0.1657  — aipw_err: 0.3776 — cate_err: 0.6145 — cate_nn_err: 2.7926 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 16.4683 - standard_loss: 11.2174 - regression_loss: 10.5954 - treatment_acc: 0.8122 - val_loss: 19.9825 - val_standard_loss: 13.9061 - val_regression_loss: 13.2892 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 110/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.0314 - standard_loss: 13.3381 - regression_loss: 12.7121 - treatment_acc: 0.7812 — ate_err: 0.1648  — aipw_err: 0.3763 — cate_err: 0.6134 — cate_nn_err: 2.7925 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.4811 - standard_loss: 11.2081 - regression_loss: 10.5861 - treatment_acc: 0.8122 - val_loss: 19.9691 - val_standard_loss: 13.8930 - val_regression_loss: 13.2762 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 111/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.4635 - standard_loss: 11.7702 - regression_loss: 11.1406 - treatment_acc: 0.7969 — ate_err: 0.1657  — aipw_err: 0.3762 — cate_err: 0.6134 — cate_nn_err: 2.7958 \n",
      "10/10 [==============================] - 0s 38ms/step - loss: 16.1540 - standard_loss: 11.2099 - regression_loss: 10.5892 - treatment_acc: 0.8186 - val_loss: 19.9573 - val_standard_loss: 13.8828 - val_regression_loss: 13.2661 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 112/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.2609 - standard_loss: 12.5677 - regression_loss: 11.9462 - treatment_acc: 0.7812 — ate_err: 0.1674  — aipw_err: 0.3769 — cate_err: 0.6140 — cate_nn_err: 2.7949 \n",
      "10/10 [==============================] - 0s 50ms/step - loss: 16.2368 - standard_loss: 11.2102 - regression_loss: 10.5880 - treatment_acc: 0.8122 - val_loss: 19.9668 - val_standard_loss: 13.8928 - val_regression_loss: 13.2764 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - ETA: 0s - loss: 16.2019 - standard_loss: 11.1985 - regression_loss: 10.5745 - treatment_acc: 0.8026 — ate_err: 0.1633  — aipw_err: 0.3756 — cate_err: 0.6129 — cate_nn_err: 2.7981 \n",
      "10/10 [==============================] - 0s 34ms/step - loss: 16.2019 - standard_loss: 11.1985 - regression_loss: 10.5745 - treatment_acc: 0.8026 - val_loss: 19.9617 - val_standard_loss: 13.8885 - val_regression_loss: 13.2722 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 114/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.9415 - standard_loss: 11.2483 - regression_loss: 10.6110 - treatment_acc: 0.7500 — ate_err: 0.1688  — aipw_err: 0.3764 — cate_err: 0.6135 — cate_nn_err: 2.7997 \n",
      "10/10 [==============================] - 0s 31ms/step - loss: 16.3938 - standard_loss: 11.1911 - regression_loss: 10.5696 - treatment_acc: 0.8122 - val_loss: 19.9364 - val_standard_loss: 13.8646 - val_regression_loss: 13.2484 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 115/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.3481 - standard_loss: 9.6550 - regression_loss: 9.0259 - treatment_acc: 0.7812 — ate_err: 0.1757  — aipw_err: 0.3793 — cate_err: 0.6159 — cate_nn_err: 2.8029 \n",
      "10/10 [==============================] - 0s 42ms/step - loss: 16.2136 - standard_loss: 11.1961 - regression_loss: 10.5724 - treatment_acc: 0.8058 - val_loss: 19.9317 - val_standard_loss: 13.8597 - val_regression_loss: 13.2437 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 116/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.7017 - standard_loss: 10.0086 - regression_loss: 9.3873 - treatment_acc: 0.8125\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      " — ate_err: 0.1704  — aipw_err: 0.3763 — cate_err: 0.6134 — cate_nn_err: 2.7988 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.2554 - standard_loss: 11.1823 - regression_loss: 10.5603 - treatment_acc: 0.8090 - val_loss: 19.9269 - val_standard_loss: 13.8566 - val_regression_loss: 13.2407 - val_treatment_acc: 0.8395 - lr: 2.5000e-06\n",
      "Epoch 117/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.6201 - standard_loss: 12.9271 - regression_loss: 12.3145 - treatment_acc: 0.8281 — ate_err: 0.1631  — aipw_err: 0.3729 — cate_err: 0.6106 — cate_nn_err: 2.7985 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.4039 - standard_loss: 11.1770 - regression_loss: 10.5552 - treatment_acc: 0.8090 - val_loss: 19.9158 - val_standard_loss: 13.8475 - val_regression_loss: 13.2317 - val_treatment_acc: 0.8395 - lr: 1.2500e-06\n",
      "Epoch 118/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.9351 - standard_loss: 13.2420 - regression_loss: 12.6347 - treatment_acc: 0.8438 — ate_err: 0.1612  — aipw_err: 0.3717 — cate_err: 0.6097 — cate_nn_err: 2.8008 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.4798 - standard_loss: 11.1694 - regression_loss: 10.5479 - treatment_acc: 0.8122 - val_loss: 19.9139 - val_standard_loss: 13.8452 - val_regression_loss: 13.2296 - val_treatment_acc: 0.8395 - lr: 1.2500e-06\n",
      "Epoch 119/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.9648 - standard_loss: 13.2718 - regression_loss: 12.6381 - treatment_acc: 0.7656 — ate_err: 0.1678  — aipw_err: 0.3735 — cate_err: 0.6112 — cate_nn_err: 2.8010 \n",
      "10/10 [==============================] - 0s 31ms/step - loss: 16.2627 - standard_loss: 11.1688 - regression_loss: 10.5483 - treatment_acc: 0.8154 - val_loss: 19.9073 - val_standard_loss: 13.8389 - val_regression_loss: 13.2233 - val_treatment_acc: 0.8395 - lr: 1.2500e-06\n",
      "Epoch 120/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.8168 - standard_loss: 11.1238 - regression_loss: 10.4932 - treatment_acc: 0.7812 — ate_err: 0.1696  — aipw_err: 0.3741 — cate_err: 0.6117 — cate_nn_err: 2.8014 \n",
      "10/10 [==============================] - 0s 31ms/step - loss: 16.3646 - standard_loss: 11.1632 - regression_loss: 10.5437 - treatment_acc: 0.8186 - val_loss: 19.9025 - val_standard_loss: 13.8343 - val_regression_loss: 13.2188 - val_treatment_acc: 0.8395 - lr: 1.2500e-06\n",
      "Epoch 121/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.5738 - standard_loss: 14.8808 - regression_loss: 14.2711 - treatment_acc: 0.8281\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      " — ate_err: 0.1680  — aipw_err: 0.3737 — cate_err: 0.6113 — cate_nn_err: 2.7989 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.4067 - standard_loss: 11.1602 - regression_loss: 10.5406 - treatment_acc: 0.8154 - val_loss: 19.9023 - val_standard_loss: 13.8342 - val_regression_loss: 13.2187 - val_treatment_acc: 0.8395 - lr: 1.2500e-06\n",
      "Epoch 122/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.1078 - standard_loss: 9.4148 - regression_loss: 8.8073 - treatment_acc: 0.8594 — ate_err: 0.1626  — aipw_err: 0.3717 — cate_err: 0.6097 — cate_nn_err: 2.7983 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.3880 - standard_loss: 11.1592 - regression_loss: 10.5374 - treatment_acc: 0.8090 - val_loss: 19.9012 - val_standard_loss: 13.8340 - val_regression_loss: 13.2187 - val_treatment_acc: 0.8395 - lr: 6.2500e-07\n",
      "Epoch 123/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.5641 - standard_loss: 13.8712 - regression_loss: 13.2512 - treatment_acc: 0.8125 — ate_err: 0.1632  — aipw_err: 0.3720 — cate_err: 0.6099 — cate_nn_err: 2.7986 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.3387 - standard_loss: 11.1566 - regression_loss: 10.5343 - treatment_acc: 0.8090 - val_loss: 19.8961 - val_standard_loss: 13.8297 - val_regression_loss: 13.2144 - val_treatment_acc: 0.8395 - lr: 6.2500e-07\n",
      "Epoch 124/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.6073 - standard_loss: 11.9143 - regression_loss: 11.3112 - treatment_acc: 0.8750 — ate_err: 0.1631  — aipw_err: 0.3719 — cate_err: 0.6099 — cate_nn_err: 2.7985 \n",
      "10/10 [==============================] - 0s 34ms/step - loss: 16.3805 - standard_loss: 11.1554 - regression_loss: 10.5328 - treatment_acc: 0.8058 - val_loss: 19.8949 - val_standard_loss: 13.8287 - val_regression_loss: 13.2134 - val_treatment_acc: 0.8395 - lr: 6.2500e-07\n",
      "Epoch 125/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.7311 - standard_loss: 12.0382 - regression_loss: 11.4155 - treatment_acc: 0.8281 — ate_err: 0.1646  — aipw_err: 0.3722 — cate_err: 0.6100 — cate_nn_err: 2.7984 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.4172 - standard_loss: 11.1506 - regression_loss: 10.5320 - treatment_acc: 0.8186 - val_loss: 19.8923 - val_standard_loss: 13.8263 - val_regression_loss: 13.2110 - val_treatment_acc: 0.8395 - lr: 6.2500e-07\n",
      "Epoch 126/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.9261 - standard_loss: 12.2332 - regression_loss: 11.6175 - treatment_acc: 0.8281\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      " — ate_err: 0.1632  — aipw_err: 0.3720 — cate_err: 0.6099 — cate_nn_err: 2.7987 \n",
      "10/10 [==============================] - 0s 37ms/step - loss: 16.3583 - standard_loss: 11.1545 - regression_loss: 10.5322 - treatment_acc: 0.8058 - val_loss: 19.8907 - val_standard_loss: 13.8249 - val_regression_loss: 13.2098 - val_treatment_acc: 0.8395 - lr: 6.2500e-07\n",
      "Epoch 127/300\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 16.6334 - standard_loss: 11.9405 - regression_loss: 11.3198 - treatment_acc: 0.8108 — ate_err: 0.1642  — aipw_err: 0.3721 — cate_err: 0.6100 — cate_nn_err: 2.7988 \n",
      "10/10 [==============================] - 0s 39ms/step - loss: 16.3553 - standard_loss: 11.1499 - regression_loss: 10.5294 - treatment_acc: 0.8154 - val_loss: 19.8869 - val_standard_loss: 13.8215 - val_regression_loss: 13.2064 - val_treatment_acc: 0.8395 - lr: 3.1250e-07\n",
      "Epoch 128/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.8463 - standard_loss: 11.1534 - regression_loss: 10.5396 - treatment_acc: 0.8281 — ate_err: 0.1665  — aipw_err: 0.3728 — cate_err: 0.6106 — cate_nn_err: 2.7991 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.3590 - standard_loss: 11.1478 - regression_loss: 10.5290 - treatment_acc: 0.8186 - val_loss: 19.8839 - val_standard_loss: 13.8188 - val_regression_loss: 13.2037 - val_treatment_acc: 0.8395 - lr: 3.1250e-07\n",
      "Epoch 129/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.7045 - standard_loss: 10.0116 - regression_loss: 9.3788 - treatment_acc: 0.7812 — ate_err: 0.1646  — aipw_err: 0.3720 — cate_err: 0.6099 — cate_nn_err: 2.7988 \n",
      "10/10 [==============================] - 0s 34ms/step - loss: 16.2674 - standard_loss: 11.1507 - regression_loss: 10.5293 - treatment_acc: 0.8090 - val_loss: 19.8837 - val_standard_loss: 13.8187 - val_regression_loss: 13.2036 - val_treatment_acc: 0.8395 - lr: 3.1250e-07\n",
      "Epoch 130/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.3883 - standard_loss: 12.6954 - regression_loss: 12.0658 - treatment_acc: 0.7969 — ate_err: 0.1672  — aipw_err: 0.3728 — cate_err: 0.6105 — cate_nn_err: 2.7989 \n",
      "10/10 [==============================] - 0s 42ms/step - loss: 16.4052 - standard_loss: 11.1494 - regression_loss: 10.5270 - treatment_acc: 0.8058 - val_loss: 19.8823 - val_standard_loss: 13.8174 - val_regression_loss: 13.2023 - val_treatment_acc: 0.8395 - lr: 3.1250e-07\n",
      "Epoch 131/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.1606 - standard_loss: 10.4678 - regression_loss: 9.8441 - treatment_acc: 0.7969\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      " — ate_err: 0.1684  — aipw_err: 0.3731 — cate_err: 0.6108 — cate_nn_err: 2.7991 \n",
      "10/10 [==============================] - 0s 45ms/step - loss: 16.2742 - standard_loss: 11.1481 - regression_loss: 10.5271 - treatment_acc: 0.8122 - val_loss: 19.8803 - val_standard_loss: 13.8154 - val_regression_loss: 13.2003 - val_treatment_acc: 0.8395 - lr: 3.1250e-07\n",
      "Epoch 132/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.6228 - standard_loss: 11.9299 - regression_loss: 11.3106 - treatment_acc: 0.7969 — ate_err: 0.1682  — aipw_err: 0.3730 — cate_err: 0.6108 — cate_nn_err: 2.7991 \n",
      "10/10 [==============================] - 0s 35ms/step - loss: 16.3731 - standard_loss: 11.1462 - regression_loss: 10.5256 - treatment_acc: 0.8122 - val_loss: 19.8798 - val_standard_loss: 13.8149 - val_regression_loss: 13.1999 - val_treatment_acc: 0.8395 - lr: 1.5625e-07\n",
      "Epoch 133/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.5870 - standard_loss: 10.8941 - regression_loss: 10.2649 - treatment_acc: 0.7500 — ate_err: 0.1682  — aipw_err: 0.3730 — cate_err: 0.6107 — cate_nn_err: 2.7991 \n",
      "10/10 [==============================] - 0s 35ms/step - loss: 16.2775 - standard_loss: 11.1462 - regression_loss: 10.5253 - treatment_acc: 0.8122 - val_loss: 19.8793 - val_standard_loss: 13.8146 - val_regression_loss: 13.1996 - val_treatment_acc: 0.8395 - lr: 1.5625e-07\n",
      "Epoch 134/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.4464 - standard_loss: 12.7535 - regression_loss: 12.1379 - treatment_acc: 0.8125 — ate_err: 0.1682  — aipw_err: 0.3730 — cate_err: 0.6107 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 31ms/step - loss: 16.2204 - standard_loss: 11.1449 - regression_loss: 10.5251 - treatment_acc: 0.8154 - val_loss: 19.8796 - val_standard_loss: 13.8148 - val_regression_loss: 13.1998 - val_treatment_acc: 0.8395 - lr: 1.5625e-07\n",
      "Epoch 135/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.7816 - standard_loss: 10.0888 - regression_loss: 9.4656 - treatment_acc: 0.7969 — ate_err: 0.1668  — aipw_err: 0.3724 — cate_err: 0.6103 — cate_nn_err: 2.7988 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.3623 - standard_loss: 11.1473 - regression_loss: 10.5249 - treatment_acc: 0.8058 - val_loss: 19.8796 - val_standard_loss: 13.8150 - val_regression_loss: 13.1999 - val_treatment_acc: 0.8395 - lr: 1.5625e-07\n",
      "Epoch 136/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.1767 - standard_loss: 10.4838 - regression_loss: 9.8902 - treatment_acc: 0.9062\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      " — ate_err: 0.1669  — aipw_err: 0.3725 — cate_err: 0.6103 — cate_nn_err: 2.7989 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.2890 - standard_loss: 11.1446 - regression_loss: 10.5240 - treatment_acc: 0.8090 - val_loss: 19.8790 - val_standard_loss: 13.8144 - val_regression_loss: 13.1994 - val_treatment_acc: 0.8395 - lr: 1.5625e-07\n",
      "Epoch 137/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.1832 - standard_loss: 12.4903 - regression_loss: 11.8513 - treatment_acc: 0.7344 — ate_err: 0.1673  — aipw_err: 0.3726 — cate_err: 0.6104 — cate_nn_err: 2.7989 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 16.3415 - standard_loss: 11.1431 - regression_loss: 10.5239 - treatment_acc: 0.8154 - val_loss: 19.8783 - val_standard_loss: 13.8139 - val_regression_loss: 13.1989 - val_treatment_acc: 0.8395 - lr: 7.8125e-08\n",
      "Epoch 138/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.1287 - standard_loss: 11.4358 - regression_loss: 10.8160 - treatment_acc: 0.7969 — ate_err: 0.1671  — aipw_err: 0.3725 — cate_err: 0.6103 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 16.2940 - standard_loss: 11.1435 - regression_loss: 10.5237 - treatment_acc: 0.8154 - val_loss: 19.8774 - val_standard_loss: 13.8130 - val_regression_loss: 13.1980 - val_treatment_acc: 0.8395 - lr: 7.8125e-08\n",
      "Epoch 139/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.8224 - standard_loss: 12.1295 - regression_loss: 11.5070 - treatment_acc: 0.8125 — ate_err: 0.1667  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 35ms/step - loss: 16.3744 - standard_loss: 11.1439 - regression_loss: 10.5235 - treatment_acc: 0.8122 - val_loss: 19.8776 - val_standard_loss: 13.8132 - val_regression_loss: 13.1982 - val_treatment_acc: 0.8395 - lr: 7.8125e-08\n",
      "Epoch 140/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.0414 - standard_loss: 10.3485 - regression_loss: 9.7224 - treatment_acc: 0.7969 — ate_err: 0.1671  — aipw_err: 0.3725 — cate_err: 0.6103 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.1668 - standard_loss: 11.1438 - regression_loss: 10.5232 - treatment_acc: 0.8122 - val_loss: 19.8773 - val_standard_loss: 13.8129 - val_regression_loss: 13.1979 - val_treatment_acc: 0.8395 - lr: 7.8125e-08\n",
      "Epoch 141/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.0553 - standard_loss: 8.3625 - regression_loss: 7.7213 - treatment_acc: 0.7500\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      " — ate_err: 0.1668  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 16.2565 - standard_loss: 11.1423 - regression_loss: 10.5232 - treatment_acc: 0.8154 - val_loss: 19.8772 - val_standard_loss: 13.8129 - val_regression_loss: 13.1979 - val_treatment_acc: 0.8395 - lr: 7.8125e-08\n",
      "Epoch 142/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 20.6961 - standard_loss: 16.0033 - regression_loss: 15.3535 - treatment_acc: 0.7188 — ate_err: 0.1669  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.1932 - standard_loss: 11.1447 - regression_loss: 10.5227 - treatment_acc: 0.8090 - val_loss: 19.8769 - val_standard_loss: 13.8126 - val_regression_loss: 13.1976 - val_treatment_acc: 0.8395 - lr: 3.9062e-08\n",
      "Epoch 143/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.8227 - standard_loss: 11.1298 - regression_loss: 10.4931 - treatment_acc: 0.7656 — ate_err: 0.1669  — aipw_err: 0.3723 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 39ms/step - loss: 16.4729 - standard_loss: 11.1415 - regression_loss: 10.5229 - treatment_acc: 0.8186 - val_loss: 19.8765 - val_standard_loss: 13.8122 - val_regression_loss: 13.1972 - val_treatment_acc: 0.8395 - lr: 3.9062e-08\n",
      "Epoch 144/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.2404 - standard_loss: 12.5476 - regression_loss: 11.9120 - treatment_acc: 0.7656 — ate_err: 0.1668  — aipw_err: 0.3723 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 43ms/step - loss: 16.1656 - standard_loss: 11.1432 - regression_loss: 10.5226 - treatment_acc: 0.8090 - val_loss: 19.8765 - val_standard_loss: 13.8122 - val_regression_loss: 13.1972 - val_treatment_acc: 0.8395 - lr: 3.9062e-08\n",
      "Epoch 145/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 12.7300 - standard_loss: 8.0372 - regression_loss: 7.3752 - treatment_acc: 0.6719 — ate_err: 0.1673  — aipw_err: 0.3725 — cate_err: 0.6103 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 31ms/step - loss: 16.3392 - standard_loss: 11.1429 - regression_loss: 10.5228 - treatment_acc: 0.8154 - val_loss: 19.8762 - val_standard_loss: 13.8119 - val_regression_loss: 13.1970 - val_treatment_acc: 0.8395 - lr: 3.9062e-08\n",
      "Epoch 146/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.3273 - standard_loss: 11.6345 - regression_loss: 11.0121 - treatment_acc: 0.7969\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      " — ate_err: 0.1673  — aipw_err: 0.3725 — cate_err: 0.6103 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.3329 - standard_loss: 11.1430 - regression_loss: 10.5225 - treatment_acc: 0.8122 - val_loss: 19.8761 - val_standard_loss: 13.8119 - val_regression_loss: 13.1969 - val_treatment_acc: 0.8395 - lr: 3.9062e-08\n",
      "Epoch 147/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 20.1243 - standard_loss: 15.4315 - regression_loss: 14.8163 - treatment_acc: 0.8594 — ate_err: 0.1673  — aipw_err: 0.3725 — cate_err: 0.6103 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 36ms/step - loss: 16.2730 - standard_loss: 11.1415 - regression_loss: 10.5223 - treatment_acc: 0.8154 - val_loss: 19.8761 - val_standard_loss: 13.8119 - val_regression_loss: 13.1969 - val_treatment_acc: 0.8395 - lr: 1.9531e-08\n",
      "Epoch 148/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.1687 - standard_loss: 13.4759 - regression_loss: 12.8629 - treatment_acc: 0.8281 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6103 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.1959 - standard_loss: 11.1413 - regression_loss: 10.5223 - treatment_acc: 0.8186 - val_loss: 19.8761 - val_standard_loss: 13.8119 - val_regression_loss: 13.1969 - val_treatment_acc: 0.8395 - lr: 1.9531e-08\n",
      "Epoch 149/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.7042 - standard_loss: 10.0114 - regression_loss: 9.3909 - treatment_acc: 0.8125 — ate_err: 0.1670  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.0889 - standard_loss: 11.1410 - regression_loss: 10.5222 - treatment_acc: 0.8186 - val_loss: 19.8761 - val_standard_loss: 13.8118 - val_regression_loss: 13.1969 - val_treatment_acc: 0.8395 - lr: 1.9531e-08\n",
      "Epoch 150/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.0738 - standard_loss: 12.3809 - regression_loss: 11.7759 - treatment_acc: 0.8750 — ate_err: 0.1670  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 16.2778 - standard_loss: 11.1474 - regression_loss: 10.5223 - treatment_acc: 0.7962 - val_loss: 19.8761 - val_standard_loss: 13.8119 - val_regression_loss: 13.1969 - val_treatment_acc: 0.8395 - lr: 1.9531e-08\n",
      "Epoch 151/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.1955 - standard_loss: 12.5027 - regression_loss: 11.8751 - treatment_acc: 0.7812 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6103 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 26ms/step - loss: 16.3937 - standard_loss: 11.1402 - regression_loss: 10.5222 - treatment_acc: 0.8218 - val_loss: 19.8759 - val_standard_loss: 13.8116 - val_regression_loss: 13.1967 - val_treatment_acc: 0.8395 - lr: 1.9531e-08\n",
      "Epoch 152/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.1563 - standard_loss: 9.4634 - regression_loss: 8.8293 - treatment_acc: 0.7500 — ate_err: 0.1672  — aipw_err: 0.3724 — cate_err: 0.6103 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.2193 - standard_loss: 11.1442 - regression_loss: 10.5221 - treatment_acc: 0.8090 - val_loss: 19.8758 - val_standard_loss: 13.8116 - val_regression_loss: 13.1966 - val_treatment_acc: 0.8395 - lr: 1.9531e-08\n",
      "Epoch 153/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.5789 - standard_loss: 8.8860 - regression_loss: 8.2649 - treatment_acc: 0.7969 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 16.1856 - standard_loss: 11.1399 - regression_loss: 10.5221 - treatment_acc: 0.8218 - val_loss: 19.8758 - val_standard_loss: 13.8116 - val_regression_loss: 13.1966 - val_treatment_acc: 0.8395 - lr: 1.9531e-08\n",
      "Epoch 154/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.3844 - standard_loss: 13.6915 - regression_loss: 13.0591 - treatment_acc: 0.7656\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.4054 - standard_loss: 11.1423 - regression_loss: 10.5220 - treatment_acc: 0.8122 - val_loss: 19.8757 - val_standard_loss: 13.8115 - val_regression_loss: 13.1966 - val_treatment_acc: 0.8395 - lr: 1.9531e-08\n",
      "Epoch 155/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.9359 - standard_loss: 14.2431 - regression_loss: 13.6281 - treatment_acc: 0.8281 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 33ms/step - loss: 16.3253 - standard_loss: 11.1406 - regression_loss: 10.5220 - treatment_acc: 0.8186 - val_loss: 19.8757 - val_standard_loss: 13.8115 - val_regression_loss: 13.1966 - val_treatment_acc: 0.8395 - lr: 9.7656e-09\n",
      "Epoch 156/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.7151 - standard_loss: 9.0223 - regression_loss: 8.4112 - treatment_acc: 0.8438 — ate_err: 0.1670  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 37ms/step - loss: 16.1429 - standard_loss: 11.1424 - regression_loss: 10.5220 - treatment_acc: 0.8122 - val_loss: 19.8756 - val_standard_loss: 13.8114 - val_regression_loss: 13.1965 - val_treatment_acc: 0.8395 - lr: 9.7656e-09\n",
      "Epoch 157/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.2109 - standard_loss: 12.5180 - regression_loss: 11.9042 - treatment_acc: 0.8281 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 39ms/step - loss: 16.3276 - standard_loss: 11.1390 - regression_loss: 10.5220 - treatment_acc: 0.8218 - val_loss: 19.8756 - val_standard_loss: 13.8114 - val_regression_loss: 13.1964 - val_treatment_acc: 0.8395 - lr: 9.7656e-09\n",
      "Epoch 158/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.5791 - standard_loss: 14.8863 - regression_loss: 14.2729 - treatment_acc: 0.8438 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 50ms/step - loss: 16.3328 - standard_loss: 11.1440 - regression_loss: 10.5220 - treatment_acc: 0.8058 - val_loss: 19.8755 - val_standard_loss: 13.8114 - val_regression_loss: 13.1964 - val_treatment_acc: 0.8395 - lr: 9.7656e-09\n",
      "Epoch 159/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.5889 - standard_loss: 8.8960 - regression_loss: 8.2945 - treatment_acc: 0.9062\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 38ms/step - loss: 16.2815 - standard_loss: 11.1417 - regression_loss: 10.5219 - treatment_acc: 0.8154 - val_loss: 19.8755 - val_standard_loss: 13.8113 - val_regression_loss: 13.1964 - val_treatment_acc: 0.8395 - lr: 9.7656e-09\n",
      "Epoch 160/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.6102 - standard_loss: 10.9173 - regression_loss: 10.2861 - treatment_acc: 0.7812 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 16.3818 - standard_loss: 11.1408 - regression_loss: 10.5219 - treatment_acc: 0.8186 - val_loss: 19.8755 - val_standard_loss: 13.8113 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 4.8828e-09\n",
      "Epoch 161/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.3642 - standard_loss: 10.6714 - regression_loss: 10.0685 - treatment_acc: 0.8750 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.2411 - standard_loss: 11.1426 - regression_loss: 10.5219 - treatment_acc: 0.8090 - val_loss: 19.8755 - val_standard_loss: 13.8113 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 4.8828e-09\n",
      "Epoch 162/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.9561 - standard_loss: 13.2632 - regression_loss: 12.6307 - treatment_acc: 0.7812 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.3852 - standard_loss: 11.1437 - regression_loss: 10.5219 - treatment_acc: 0.8090 - val_loss: 19.8755 - val_standard_loss: 13.8113 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 4.8828e-09\n",
      "Epoch 163/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.3468 - standard_loss: 14.6539 - regression_loss: 14.0168 - treatment_acc: 0.7500 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.3769 - standard_loss: 11.1406 - regression_loss: 10.5219 - treatment_acc: 0.8186 - val_loss: 19.8755 - val_standard_loss: 13.8113 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 4.8828e-09\n",
      "Epoch 164/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.8245 - standard_loss: 11.1316 - regression_loss: 10.5053 - treatment_acc: 0.8125\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 33ms/step - loss: 16.1906 - standard_loss: 11.1420 - regression_loss: 10.5219 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8113 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 4.8828e-09\n",
      "Epoch 165/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.7222 - standard_loss: 14.0294 - regression_loss: 13.4228 - treatment_acc: 0.8594 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.3132 - standard_loss: 11.1437 - regression_loss: 10.5218 - treatment_acc: 0.8058 - val_loss: 19.8754 - val_standard_loss: 13.8113 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 2.4414e-09\n",
      "Epoch 166/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.8935 - standard_loss: 10.2007 - regression_loss: 9.5912 - treatment_acc: 0.8438 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 26ms/step - loss: 16.3623 - standard_loss: 11.1436 - regression_loss: 10.5218 - treatment_acc: 0.8058 - val_loss: 19.8754 - val_standard_loss: 13.8113 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 2.4414e-09\n",
      "Epoch 167/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.8654 - standard_loss: 10.1726 - regression_loss: 9.5603 - treatment_acc: 0.8281 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 16.3682 - standard_loss: 11.1428 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8113 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 2.4414e-09\n",
      "Epoch 168/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.3044 - standard_loss: 13.6115 - regression_loss: 12.9791 - treatment_acc: 0.7656 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 33ms/step - loss: 16.3984 - standard_loss: 11.1393 - regression_loss: 10.5218 - treatment_acc: 0.8218 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 2.4414e-09\n",
      "Epoch 169/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.7716 - standard_loss: 9.0788 - regression_loss: 8.4631 - treatment_acc: 0.8438\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 34ms/step - loss: 16.2837 - standard_loss: 11.1399 - regression_loss: 10.5218 - treatment_acc: 0.8218 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 2.4414e-09\n",
      "Epoch 170/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.8237 - standard_loss: 9.1308 - regression_loss: 8.5214 - treatment_acc: 0.8438 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.3237 - standard_loss: 11.1456 - regression_loss: 10.5218 - treatment_acc: 0.7994 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.2207e-09\n",
      "Epoch 171/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.2719 - standard_loss: 11.5790 - regression_loss: 10.9556 - treatment_acc: 0.7969 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 16.1917 - standard_loss: 11.1411 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.2207e-09\n",
      "Epoch 172/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.9656 - standard_loss: 9.2728 - regression_loss: 8.6678 - treatment_acc: 0.8750 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 31ms/step - loss: 16.2524 - standard_loss: 11.1420 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.2207e-09\n",
      "Epoch 173/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.9232 - standard_loss: 9.2303 - regression_loss: 8.5877 - treatment_acc: 0.7188 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 36ms/step - loss: 16.2818 - standard_loss: 11.1428 - regression_loss: 10.5218 - treatment_acc: 0.8090 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.2207e-09\n",
      "Epoch 174/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.9438 - standard_loss: 11.2510 - regression_loss: 10.6095 - treatment_acc: 0.7500\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-10.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 31ms/step - loss: 16.3220 - standard_loss: 11.1421 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.2207e-09\n",
      "Epoch 175/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.5721 - standard_loss: 12.8792 - regression_loss: 12.2731 - treatment_acc: 0.8594 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.3700 - standard_loss: 11.1418 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 6.1035e-10\n",
      "Epoch 176/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.9120 - standard_loss: 12.2192 - regression_loss: 11.6177 - treatment_acc: 0.8906 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.3844 - standard_loss: 11.1449 - regression_loss: 10.5218 - treatment_acc: 0.8026 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 6.1035e-10\n",
      "Epoch 177/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.9719 - standard_loss: 12.2790 - regression_loss: 11.6772 - treatment_acc: 0.8750 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 26ms/step - loss: 16.2618 - standard_loss: 11.1424 - regression_loss: 10.5218 - treatment_acc: 0.8090 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 6.1035e-10\n",
      "Epoch 178/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.0783 - standard_loss: 13.3854 - regression_loss: 12.7623 - treatment_acc: 0.7812 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.3523 - standard_loss: 11.1422 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 6.1035e-10\n",
      "Epoch 179/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.7588 - standard_loss: 13.0660 - regression_loss: 12.4630 - treatment_acc: 0.8750\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-10.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 16.3032 - standard_loss: 11.1419 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 6.1035e-10\n",
      "Epoch 180/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.0136 - standard_loss: 12.3208 - regression_loss: 11.7008 - treatment_acc: 0.8125 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 35ms/step - loss: 16.3784 - standard_loss: 11.1426 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 3.0518e-10\n",
      "Epoch 181/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.4115 - standard_loss: 9.7186 - regression_loss: 9.1101 - treatment_acc: 0.8594 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 26ms/step - loss: 16.4173 - standard_loss: 11.1449 - regression_loss: 10.5218 - treatment_acc: 0.8026 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 3.0518e-10\n",
      "Epoch 182/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.6184 - standard_loss: 11.9256 - regression_loss: 11.2959 - treatment_acc: 0.7500 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.2969 - standard_loss: 11.1403 - regression_loss: 10.5218 - treatment_acc: 0.8218 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 3.0518e-10\n",
      "Epoch 183/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.3204 - standard_loss: 10.6275 - regression_loss: 10.0189 - treatment_acc: 0.8594 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 26ms/step - loss: 16.3355 - standard_loss: 11.1426 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 3.0518e-10\n",
      "Epoch 184/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.1325 - standard_loss: 11.4397 - regression_loss: 10.8299 - treatment_acc: 0.8750\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 1.5258788677030566e-10.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 26ms/step - loss: 16.4116 - standard_loss: 11.1413 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 3.0518e-10\n",
      "Epoch 185/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.2362 - standard_loss: 10.5433 - regression_loss: 9.9171 - treatment_acc: 0.7969 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.3490 - standard_loss: 11.1415 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.5259e-10\n",
      "Epoch 186/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.5233 - standard_loss: 10.8304 - regression_loss: 10.2064 - treatment_acc: 0.8125 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 25ms/step - loss: 16.3918 - standard_loss: 11.1412 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.5259e-10\n",
      "Epoch 187/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.2984 - standard_loss: 8.6055 - regression_loss: 7.9892 - treatment_acc: 0.8125 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 26ms/step - loss: 16.2448 - standard_loss: 11.1409 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.5259e-10\n",
      "Epoch 188/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.0930 - standard_loss: 14.4001 - regression_loss: 13.7977 - treatment_acc: 0.8750 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 37ms/step - loss: 16.1846 - standard_loss: 11.1403 - regression_loss: 10.5218 - treatment_acc: 0.8186 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.5259e-10\n",
      "Epoch 189/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.3173 - standard_loss: 12.6244 - regression_loss: 12.0112 - treatment_acc: 0.8281\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 7.629394338515283e-11.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.2913 - standard_loss: 11.1417 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.5259e-10\n",
      "Epoch 190/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.7622 - standard_loss: 12.0693 - regression_loss: 11.4564 - treatment_acc: 0.8281 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.3179 - standard_loss: 11.1417 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 7.6294e-11\n",
      "Epoch 191/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.0021 - standard_loss: 13.3092 - regression_loss: 12.7079 - treatment_acc: 0.8594 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 26ms/step - loss: 16.3845 - standard_loss: 11.1421 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 7.6294e-11\n",
      "Epoch 192/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.3034 - standard_loss: 12.6105 - regression_loss: 11.9766 - treatment_acc: 0.7812 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 16.4239 - standard_loss: 11.1404 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 7.6294e-11\n",
      "Epoch 193/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.9440 - standard_loss: 10.2512 - regression_loss: 9.6326 - treatment_acc: 0.7969 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 16.4256 - standard_loss: 11.1423 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 7.6294e-11\n",
      "Epoch 194/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.5448 - standard_loss: 11.8520 - regression_loss: 11.2475 - treatment_acc: 0.8750\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 3.8146971692576415e-11.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 34ms/step - loss: 16.3227 - standard_loss: 11.1425 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 7.6294e-11\n",
      "Epoch 195/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.8887 - standard_loss: 13.1958 - regression_loss: 12.5557 - treatment_acc: 0.7500 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 33ms/step - loss: 16.2838 - standard_loss: 11.1402 - regression_loss: 10.5218 - treatment_acc: 0.8186 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 3.8147e-11\n",
      "Epoch 196/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.6360 - standard_loss: 8.9432 - regression_loss: 8.3081 - treatment_acc: 0.7656 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.3337 - standard_loss: 11.1434 - regression_loss: 10.5218 - treatment_acc: 0.8090 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 3.8147e-11\n",
      "Epoch 197/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.0986 - standard_loss: 12.4057 - regression_loss: 11.7978 - treatment_acc: 0.8438 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 34ms/step - loss: 16.4552 - standard_loss: 11.1447 - regression_loss: 10.5218 - treatment_acc: 0.8058 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 3.8147e-11\n",
      "Epoch 198/300\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 16.4709 - standard_loss: 11.7781 - regression_loss: 11.1576 - treatment_acc: 0.8108 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.2472 - standard_loss: 11.1421 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 3.8147e-11\n",
      "Epoch 199/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.9205 - standard_loss: 9.2277 - regression_loss: 8.5881 - treatment_acc: 0.7500\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 1.9073485846288207e-11.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 16.3511 - standard_loss: 11.1414 - regression_loss: 10.5218 - treatment_acc: 0.8186 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 3.8147e-11\n",
      "Epoch 200/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.2146 - standard_loss: 12.5217 - regression_loss: 11.8982 - treatment_acc: 0.7969 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 41ms/step - loss: 16.4402 - standard_loss: 11.1423 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.9073e-11\n",
      "Epoch 201/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.8340 - standard_loss: 9.1411 - regression_loss: 8.5146 - treatment_acc: 0.7812 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 33ms/step - loss: 16.3879 - standard_loss: 11.1424 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.9073e-11\n",
      "Epoch 202/300\n",
      "10/10 [==============================] - ETA: 0s - loss: 16.4423 - standard_loss: 11.1441 - regression_loss: 10.5218 - treatment_acc: 0.8058 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 40ms/step - loss: 16.4423 - standard_loss: 11.1441 - regression_loss: 10.5218 - treatment_acc: 0.8058 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.9073e-11\n",
      "Epoch 203/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.1065 - standard_loss: 14.4136 - regression_loss: 13.7963 - treatment_acc: 0.8281 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 41ms/step - loss: 16.2473 - standard_loss: 11.1412 - regression_loss: 10.5218 - treatment_acc: 0.8186 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.9073e-11\n",
      "Epoch 204/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.3857 - standard_loss: 9.6928 - regression_loss: 9.0648 - treatment_acc: 0.7812\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 9.536742923144104e-12.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 33ms/step - loss: 16.3905 - standard_loss: 11.1403 - regression_loss: 10.5218 - treatment_acc: 0.8186 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.9073e-11\n",
      "Epoch 205/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.9240 - standard_loss: 13.2312 - regression_loss: 12.5824 - treatment_acc: 0.7188 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 36ms/step - loss: 16.3704 - standard_loss: 11.1425 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 9.5367e-12\n",
      "Epoch 206/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.8647 - standard_loss: 10.1718 - regression_loss: 9.5681 - treatment_acc: 0.8438 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 40ms/step - loss: 16.3037 - standard_loss: 11.1451 - regression_loss: 10.5218 - treatment_acc: 0.8026 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 9.5367e-12\n",
      "Epoch 207/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 13.9387 - standard_loss: 9.2458 - regression_loss: 8.6440 - treatment_acc: 0.8750 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 26ms/step - loss: 16.3449 - standard_loss: 11.1413 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 9.5367e-12\n",
      "Epoch 208/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.9871 - standard_loss: 15.2942 - regression_loss: 14.6628 - treatment_acc: 0.7812 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 34ms/step - loss: 16.4343 - standard_loss: 11.1424 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 9.5367e-12\n",
      "Epoch 209/300\n",
      "10/10 [==============================] - ETA: 0s - loss: 16.2961 - standard_loss: 11.1425 - regression_loss: 10.5218 - treatment_acc: 0.8122\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 4.768371461572052e-12.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 36ms/step - loss: 16.2961 - standard_loss: 11.1425 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 9.5367e-12\n",
      "Epoch 210/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 19.0224 - standard_loss: 14.3296 - regression_loss: 13.6987 - treatment_acc: 0.7656 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 16.3837 - standard_loss: 11.1444 - regression_loss: 10.5218 - treatment_acc: 0.8058 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 4.7684e-12\n",
      "Epoch 211/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.4885 - standard_loss: 11.7956 - regression_loss: 11.1899 - treatment_acc: 0.8438 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 38ms/step - loss: 16.4055 - standard_loss: 11.1401 - regression_loss: 10.5218 - treatment_acc: 0.8186 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 4.7684e-12\n",
      "Epoch 212/300\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 16.5492 - standard_loss: 11.8563 - regression_loss: 11.2350 - treatment_acc: 0.8090 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 37ms/step - loss: 16.2974 - standard_loss: 11.1405 - regression_loss: 10.5218 - treatment_acc: 0.8186 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 4.7684e-12\n",
      "Epoch 213/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.0089 - standard_loss: 13.3161 - regression_loss: 12.6892 - treatment_acc: 0.7812 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 16.3957 - standard_loss: 11.1430 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 4.7684e-12\n",
      "Epoch 214/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.1796 - standard_loss: 11.4867 - regression_loss: 10.8581 - treatment_acc: 0.7656\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 2.384185730786026e-12.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 45ms/step - loss: 16.2547 - standard_loss: 11.1406 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 4.7684e-12\n",
      "Epoch 215/300\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 16.3386 - standard_loss: 11.6457 - regression_loss: 11.0257 - treatment_acc: 0.8125 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 47ms/step - loss: 16.1618 - standard_loss: 11.1430 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 2.3842e-12\n",
      "Epoch 216/300\n",
      "10/10 [==============================] - ETA: 0s - loss: 16.2979 - standard_loss: 11.1452 - regression_loss: 10.5218 - treatment_acc: 0.8026 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 38ms/step - loss: 16.2979 - standard_loss: 11.1452 - regression_loss: 10.5218 - treatment_acc: 0.8026 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 2.3842e-12\n",
      "Epoch 217/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.0323 - standard_loss: 12.3395 - regression_loss: 11.7392 - treatment_acc: 0.8750 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.3139 - standard_loss: 11.1423 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 2.3842e-12\n",
      "Epoch 218/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.4384 - standard_loss: 10.7456 - regression_loss: 10.1304 - treatment_acc: 0.8281 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.4478 - standard_loss: 11.1432 - regression_loss: 10.5218 - treatment_acc: 0.8090 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 2.3842e-12\n",
      "Epoch 219/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.4145 - standard_loss: 9.7217 - regression_loss: 9.0944 - treatment_acc: 0.7969\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 1.192092865393013e-12.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 37ms/step - loss: 16.3123 - standard_loss: 11.1426 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 2.3842e-12\n",
      "Epoch 220/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.2579 - standard_loss: 12.5651 - regression_loss: 11.9430 - treatment_acc: 0.8125 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 16.3447 - standard_loss: 11.1418 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.1921e-12\n",
      "Epoch 221/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.1477 - standard_loss: 10.4548 - regression_loss: 9.8326 - treatment_acc: 0.8281 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 16.2801 - standard_loss: 11.1439 - regression_loss: 10.5218 - treatment_acc: 0.8058 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.1921e-12\n",
      "Epoch 222/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.3067 - standard_loss: 13.6139 - regression_loss: 13.0120 - treatment_acc: 0.8906 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 16.2634 - standard_loss: 11.1404 - regression_loss: 10.5218 - treatment_acc: 0.8186 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.1921e-12\n",
      "Epoch 223/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.9000 - standard_loss: 14.2071 - regression_loss: 13.5988 - treatment_acc: 0.8750 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 16.3512 - standard_loss: 11.1426 - regression_loss: 10.5218 - treatment_acc: 0.8122 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.1921e-12\n",
      "Epoch 224/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.4361 - standard_loss: 11.7432 - regression_loss: 11.1240 - treatment_acc: 0.8125\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 5.960464326965065e-13.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 27ms/step - loss: 16.2989 - standard_loss: 11.1385 - regression_loss: 10.5218 - treatment_acc: 0.8218 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 1.1921e-12\n",
      "Epoch 225/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 18.0719 - standard_loss: 13.3791 - regression_loss: 12.7718 - treatment_acc: 0.8750 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 33ms/step - loss: 16.3561 - standard_loss: 11.1461 - regression_loss: 10.5218 - treatment_acc: 0.7994 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 5.9605e-13\n",
      "Epoch 226/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.2703 - standard_loss: 12.5775 - regression_loss: 11.9698 - treatment_acc: 0.8750 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 37ms/step - loss: 16.3808 - standard_loss: 11.1411 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 5.9605e-13\n",
      "Epoch 227/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.9144 - standard_loss: 12.2215 - regression_loss: 11.5736 - treatment_acc: 0.7031 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.2444 - standard_loss: 11.1401 - regression_loss: 10.5218 - treatment_acc: 0.8186 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 5.9605e-13\n",
      "Epoch 228/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 15.1813 - standard_loss: 10.4884 - regression_loss: 9.8744 - treatment_acc: 0.8438 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 28ms/step - loss: 16.2980 - standard_loss: 11.1423 - regression_loss: 10.5218 - treatment_acc: 0.8090 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 5.9605e-13\n",
      "Epoch 229/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 16.2328 - standard_loss: 11.5399 - regression_loss: 10.9007 - treatment_acc: 0.7344\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 2.9802321634825324e-13.\n",
      " — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 35ms/step - loss: 16.3196 - standard_loss: 11.1436 - regression_loss: 10.5218 - treatment_acc: 0.8090 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 5.9605e-13\n",
      "Epoch 230/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 17.1099 - standard_loss: 12.4171 - regression_loss: 11.8193 - treatment_acc: 0.8906 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 29ms/step - loss: 16.3270 - standard_loss: 11.1429 - regression_loss: 10.5218 - treatment_acc: 0.8090 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 2.9802e-13\n",
      "Epoch 231/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.4970 - standard_loss: 9.8041 - regression_loss: 9.1664 - treatment_acc: 0.7656 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 32ms/step - loss: 16.2177 - standard_loss: 11.1419 - regression_loss: 10.5218 - treatment_acc: 0.8154 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 2.9802e-13\n",
      "Epoch 232/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.2327 - standard_loss: 9.5398 - regression_loss: 8.9195 - treatment_acc: 0.7969 — ate_err: 0.1671  — aipw_err: 0.3724 — cate_err: 0.6102 — cate_nn_err: 2.7990 \n",
      "10/10 [==============================] - 0s 30ms/step - loss: 16.2322 - standard_loss: 11.1428 - regression_loss: 10.5218 - treatment_acc: 0.8090 - val_loss: 19.8754 - val_standard_loss: 13.8112 - val_regression_loss: 13.1963 - val_treatment_acc: 0.8395 - lr: 2.9802e-13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1537a27c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "%load_ext tensorboard\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau, TerminateOnNaN\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "val_split=0.2\n",
    "batch_size=64\n",
    "verbose=1\n",
    "i = 0\n",
    "tf.random.set_seed(i)\n",
    "np.random.seed(i)\n",
    "yt = np.concatenate([data['ys'], data['t']], 1)\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ \n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "sgd_callbacks = [\n",
    "        TerminateOnNaN(),\n",
    "        EarlyStopping(monitor='val_loss', patience=40, min_delta=0.),\n",
    "        ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=verbose, mode='auto',\n",
    "                          min_delta=0., cooldown=0, min_lr=0),\n",
    "        tensorboard_callback,\n",
    "        AIPW_Metrics(data,verbose=verbose)\n",
    "        ]\n",
    "      \n",
    "\n",
    "sgd_lr = 1e-5\n",
    "momentum = 0.9\n",
    "\n",
    "aipw_model=make_aipw(data['x'].shape[1],.01)\n",
    "aipw_loss=Base_Loss(alpha=1.0)\n",
    "\n",
    "aipw_model.compile(optimizer=SGD(lr=sgd_lr, momentum=momentum, nesterov=True),\n",
    "                    loss=aipw_loss,\n",
    "                    metrics=[aipw_loss,aipw_loss.regression_loss,aipw_loss.treatment_acc]\n",
    "                   )\n",
    "\n",
    "aipw_model.fit(x=data['x'],y=yt,\n",
    "                  callbacks=sgd_callbacks,\n",
    "                  validation_split=val_split,\n",
    "                  epochs=300,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=verbose)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 79676), started 4:44:35 ago. (Use '!kill 79676' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4ffcd3e4006a9be0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4ffcd3e4006a9be0\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

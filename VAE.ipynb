{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3304f645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies & Prerequisites\n",
    "#@title Import { display-mode: \"form\" }\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d532ca8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: GPU device not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 18:05:26.405854: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "  print('WARNING: GPU device not found.')\n",
    "else:\n",
    "  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb91da84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 18:05:30.085040: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /Users/bytedance/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6168505675442358f69490f362daab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /Users/bytedance/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "datasets, datasets_info = tfds.load(name='mnist',\n",
    "                                    with_info=True,\n",
    "                                    as_supervised=False)\n",
    "\n",
    "def _preprocess(sample):\n",
    "    image = tf.cast(sample['image'], tf.float32) / 255.  # Scale to unit interval.\n",
    "    image = image < tf.random.uniform(tf.shape(image))   # Randomly binarize.\n",
    "    return image, image\n",
    "\n",
    "train_dataset = (datasets['train']\n",
    "                 .map(_preprocess)\n",
    "                 .batch(256)\n",
    "                 .prefetch(tf.data.AUTOTUNE)\n",
    "                 .shuffle(int(10e3)))\n",
    "eval_dataset = (datasets['test']\n",
    "                .map(_preprocess)\n",
    "                .batch(256)\n",
    "                .prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca82708",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = datasets_info.features['image'].shape\n",
    "encoded_size = 16\n",
    "base_depth = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45bb5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1),\n",
    "                        reinterpreted_batch_ndims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "863e1e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 18:06:10.137519: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "encoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=input_shape),\n",
    "    tfkl.Lambda(lambda x: tf.cast(x, tf.float32) - 0.5),\n",
    "    tfkl.Conv2D(base_depth, 5, strides=1,\n",
    "                padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2D(base_depth, 5, strides=2,\n",
    "                padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2D(2 * base_depth, 5, strides=1,\n",
    "                padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2D(2 * base_depth, 5, strides=2,\n",
    "                padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2D(4 * encoded_size, 7, strides=1,\n",
    "                padding='valid', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Flatten(),\n",
    "    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size),\n",
    "               activation=None),\n",
    "    tfpl.MultivariateNormalTriL(\n",
    "        encoded_size,\n",
    "        activity_regularizer=tfpl.KLDivergenceRegularizer(prior)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "291d7f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=[encoded_size]),\n",
    "    tfkl.Reshape([1, 1, encoded_size]),\n",
    "    tfkl.Conv2DTranspose(2 * base_depth, 7, strides=1,\n",
    "                         padding='valid', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2DTranspose(2 * base_depth, 5, strides=1,\n",
    "                         padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2DTranspose(2 * base_depth, 5, strides=2,\n",
    "                         padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2DTranspose(base_depth, 5, strides=1,\n",
    "                         padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2DTranspose(base_depth, 5, strides=2,\n",
    "                         padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2DTranspose(base_depth, 5, strides=1,\n",
    "                         padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2D(filters=1, kernel_size=5, strides=1,\n",
    "                padding='same', activation=None),\n",
    "    tfkl.Flatten(),\n",
    "    tfpl.IndependentBernoulli(input_shape, tfd.Bernoulli.logits),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31b22919",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = tfk.Model(inputs=encoder.inputs,\n",
    "                outputs=decoder(encoder.outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee3bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "235/235 [==============================] - 209s 872ms/step - loss: 240.6181 - val_loss: 175.2680\n",
      "Epoch 2/15\n",
      "235/235 [==============================] - ETA: 0s - loss: 158.4107"
     ]
    }
   ],
   "source": [
    "negloglik = lambda x, rv_x: -rv_x.log_prob(x)\n",
    "\n",
    "vae.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n",
    "            loss=negloglik)\n",
    "\n",
    "_ = vae.fit(train_dataset,\n",
    "            epochs=15,\n",
    "            validation_data=eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2890dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll just examine ten random digits.\n",
    "x = next(iter(eval_dataset))[0][:10]\n",
    "xhat = vae(x)\n",
    "assert isinstance(xhat, tfd.Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bbe08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Image Plot Util\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_imgs(x, y=None):\n",
    "    if not isinstance(x, (np.ndarray, np.generic)):\n",
    "    x = np.array(x)\n",
    "    plt.ioff()\n",
    "    n = x.shape[0]\n",
    "    fig, axs = plt.subplots(1, n, figsize=(n, 1))\n",
    "    if y is not None:\n",
    "    fig.suptitle(np.argmax(y, axis=1))\n",
    "    for i in range(n):\n",
    "    axs.flat[i].imshow(x[i].squeeze(), interpolation='none', cmap='gray')\n",
    "    axs.flat[i].axis('off')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ad07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Originals:')\n",
    "display_imgs(x)\n",
    "\n",
    "print('Decoded Random Samples:')\n",
    "display_imgs(xhat.sample())\n",
    "\n",
    "print('Decoded Modes:')\n",
    "display_imgs(xhat.mode())\n",
    "\n",
    "print('Decoded Means:')\n",
    "display_imgs(xhat.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's generate ten never-before-seen digits.\n",
    "z = prior.sample(10)\n",
    "xtilde = decoder(z)\n",
    "assert isinstance(xtilde, tfd.Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b0f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Randomly Generated Samples:')\n",
    "display_imgs(xtilde.sample())\n",
    "\n",
    "print('Randomly Generated Modes:')\n",
    "display_imgs(xtilde.mode())\n",
    "\n",
    "print('Randomly Generated Means:')\n",
    "display_imgs(xtilde.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d04d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "CEVAE moargs.latent_dimensionel on IHargs.latent_dimensionP\n",
    "\"\"\"\n",
    "##################### Neeargs.latent_dimension TF1\n",
    "# import edward as ed\n",
    "# import tensorflow as tf\n",
    "# from utils import fc_net, get_y0_y1\n",
    "# from edward.models import Bernoulli, Normal\n",
    "# from progressbar import ETA, Bar, Percentage, ProgressBar\n",
    "###############################################################\n",
    "import os\n",
    "# import json\n",
    "# import time\n",
    "# import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy.stats import sem\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.keras.layers as tfkl\n",
    "tfd,tfpl = tfp.distributions,tfp.layers\n",
    "import tensorflow.keras.backend as tfkb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import IHDP\n",
    "from evaluation import Evaluator\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "################### CEVAE\n",
    "parser.add_argument('-reps', type=int, default=10)\n",
    "parser.add_argument('-earl', type=int, default=10)\n",
    "parser.add_argument('-lr', type=float, default=0.001)\n",
    "parser.add_argument('-decay', type=float, default=0.001)\n",
    "parser.add_argument('-opt', choices=['adam', 'adamax'], default='adam')\n",
    "parser.add_argument('-epochs', type=int, default=100)     \n",
    "parser.add_argument('-print_every', type=int, default=10)\n",
    "################### BASIC\n",
    "parser.add_argument('--num_parallel_reads', type = int, default = 10, help = 'random seed')\n",
    "parser.add_argument('--random_seed', type = int,default = 9418, help = 'random seed')\n",
    "parser.add_argument('--mode', type = str, default = 'train', help = 'train or evaluate')\n",
    "args = parser.parse_args([])\n",
    "args.true_post = True\n",
    "#################################From CEVAE\n",
    "dataset = IHDP(replications=args.reps)\n",
    "dimx = 25\n",
    "scores = np.zeros((args.reps, 3))\n",
    "scores_test = np.zeros((args.reps, 3))\n",
    "#################################IHDP Data\n",
    "# data information \n",
    "t_bin_dim = 1\n",
    "y_dim, default_y_scale = 1,tf.exp(0.)\n",
    "M = None        # batch size during training\n",
    "z_dim = 20          # latent z dimension\n",
    "lamba = 1e-4    # weight decay\n",
    "nh, h = 3, 200  # number and size of hidden layers\n",
    "binfeats = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
    "numfeats = [i for i in range(25) if i not in binfeats]\n",
    "x_bin_dim = len(binfeats)\n",
    "x_num_dim = len(numfeats)\n",
    "################################# some functions needed\n",
    "def findfile(start, name):\n",
    "    ans = []\n",
    "    for relpath, dirs, files in os.walk(start):\n",
    "        for file in files:\n",
    "            if name in file:\n",
    "                full_path = os.path.join(start, file)\n",
    "                ans.append(full_path)\n",
    "                # print(os.path.normpath(os.path.abspath(full_path)))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>y_factual</th>\n",
       "      <th>y_cfactual</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>...</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>y_factual_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.267344</td>\n",
       "      <td>6.314020</td>\n",
       "      <td>6.151308</td>\n",
       "      <td>11.160778</td>\n",
       "      <td>-0.528603</td>\n",
       "      <td>-0.343455</td>\n",
       "      <td>1.128554</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>-0.316603</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.966599</td>\n",
       "      <td>9.136500</td>\n",
       "      <td>2.633272</td>\n",
       "      <td>10.312341</td>\n",
       "      <td>-1.736945</td>\n",
       "      <td>-1.802002</td>\n",
       "      <td>0.383828</td>\n",
       "      <td>2.244320</td>\n",
       "      <td>-0.629189</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.426812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.403815</td>\n",
       "      <td>10.527021</td>\n",
       "      <td>4.532332</td>\n",
       "      <td>10.855350</td>\n",
       "      <td>-0.807451</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.808706</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.466153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.471264</td>\n",
       "      <td>10.890649</td>\n",
       "      <td>4.310770</td>\n",
       "      <td>10.805230</td>\n",
       "      <td>0.390083</td>\n",
       "      <td>0.596582</td>\n",
       "      <td>-1.850350</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.461438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.531366</td>\n",
       "      <td>11.504950</td>\n",
       "      <td>5.621538</td>\n",
       "      <td>11.070719</td>\n",
       "      <td>-1.045229</td>\n",
       "      <td>-0.602710</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>0.683672</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.387333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7465</th>\n",
       "      <td>0</td>\n",
       "      <td>3.633425</td>\n",
       "      <td>9.458109</td>\n",
       "      <td>3.398584</td>\n",
       "      <td>8.162824</td>\n",
       "      <td>-0.007654</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>-0.316603</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.450102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7466</th>\n",
       "      <td>1</td>\n",
       "      <td>7.692058</td>\n",
       "      <td>5.441664</td>\n",
       "      <td>7.195693</td>\n",
       "      <td>8.912948</td>\n",
       "      <td>0.727295</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.733261</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.808706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.166389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7467</th>\n",
       "      <td>0</td>\n",
       "      <td>1.785687</td>\n",
       "      <td>9.759147</td>\n",
       "      <td>3.485027</td>\n",
       "      <td>8.187941</td>\n",
       "      <td>1.181234</td>\n",
       "      <td>0.196818</td>\n",
       "      <td>-1.477987</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>0.746189</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.579266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7468</th>\n",
       "      <td>0</td>\n",
       "      <td>8.585642</td>\n",
       "      <td>8.943839</td>\n",
       "      <td>8.154517</td>\n",
       "      <td>9.038037</td>\n",
       "      <td>-0.288664</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-1.477987</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>1.621430</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.103924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7469</th>\n",
       "      <td>0</td>\n",
       "      <td>5.665184</td>\n",
       "      <td>9.961218</td>\n",
       "      <td>6.349958</td>\n",
       "      <td>8.787913</td>\n",
       "      <td>-0.137351</td>\n",
       "      <td>0.596582</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.496120</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.308075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7470 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      treatment  y_factual  y_cfactual       mu0        mu1        x0  \\\n",
       "0             1  11.267344    6.314020  6.151308  11.160778 -0.528603   \n",
       "1             0   3.966599    9.136500  2.633272  10.312341 -1.736945   \n",
       "2             0   3.403815   10.527021  4.532332  10.855350 -0.807451   \n",
       "3             0   3.471264   10.890649  4.310770  10.805230  0.390083   \n",
       "4             0   4.531366   11.504950  5.621538  11.070719 -1.045229   \n",
       "...         ...        ...         ...       ...        ...       ...   \n",
       "7465          0   3.633425    9.458109  3.398584   8.162824 -0.007654   \n",
       "7466          1   7.692058    5.441664  7.195693   8.912948  0.727295   \n",
       "7467          0   1.785687    9.759147  3.485027   8.187941  1.181234   \n",
       "7468          0   8.585642    8.943839  8.154517   9.038037 -0.288664   \n",
       "7469          0   5.665184    9.961218  6.349958   8.787913 -0.137351   \n",
       "\n",
       "            x1        x2        x3        x4  ...  x16  x17  x18  x19  x20  \\\n",
       "0    -0.343455  1.128554  0.161703 -0.316603  ...    1    1    1    0    0   \n",
       "1    -1.802002  0.383828  2.244320 -0.629189  ...    1    1    1    0    0   \n",
       "2    -0.202946 -0.360898 -0.879606  0.808706  ...    0    1    1    0    0   \n",
       "3     0.596582 -1.850350 -0.879606 -0.004017  ...    0    1    1    0    0   \n",
       "4    -0.602710  0.011465  0.161703  0.683672  ...    1    1    1    0    0   \n",
       "...        ...       ...       ...       ...  ...  ...  ...  ...  ...  ...   \n",
       "7465 -0.202946 -0.360898  0.161703 -0.316603  ...    0    1    0    0    0   \n",
       "7466 -0.202946 -0.733261 -0.879606  0.808706  ...    1    1    0    0    0   \n",
       "7467  0.196818 -1.477987  0.161703  0.746189  ...    1    1    0    0    0   \n",
       "7468 -0.202946 -1.477987 -0.879606  1.621430  ...    1    1    0    0    0   \n",
       "7469  0.596582 -0.360898 -0.879606  0.496120  ...    1    1    0    0    0   \n",
       "\n",
       "      x21  x22  x23  x24  y_factual_scale  \n",
       "0       0    0    0    0         0.083537  \n",
       "1       0    0    0    0        -0.426812  \n",
       "2       0    0    0    0        -0.466153  \n",
       "3       0    0    0    0        -0.461438  \n",
       "4       0    0    0    0        -0.387333  \n",
       "...   ...  ...  ...  ...              ...  \n",
       "7465    0    0    0    0        -0.450102  \n",
       "7466    0    0    0    0        -0.166389  \n",
       "7467    0    0    0    0        -0.579266  \n",
       "7468    0    0    0    0        -0.103924  \n",
       "7469    0    0    0    0        -0.308075  \n",
       "\n",
       "[7470 rows x 31 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# get data\n",
    "data_all = []\n",
    "for data in findfile(\"./datasets/IHDP/csv\",'.csv'):\n",
    "    try:\n",
    "        data_all = data_all.append(pd.read_csv(data, header = None), ignore_index = True)\n",
    "    except:\n",
    "        data_all = pd.read_csv(data, header = None)\n",
    "data_all.columns = ['treatment', 'y_factual', 'y_cfactual', 'mu0', 'mu1', ] + ['x'+str(i) for i in range(25)]\n",
    "# process\n",
    "y_mean,y_std = np.mean(data_all['y_factual']),np.std(data_all['y_factual'])\n",
    "data_all['y_factual_scale'] = (data_all['y_factual'] - y_mean) / y_std\n",
    "data_all['x13'] = data_all['x13'] - 1\n",
    "# set random seeds:\n",
    "np.random.seed(7)\n",
    "data_train, data_valid = train_test_split(data_all, test_size=0.2, )\n",
    "# data_train.to_csv(\"./datasets/IHDP/csv_create/train.csv\", header = None, index =None)\n",
    "# data_valid.to_csv(\"./datasets/IHDP/csv_create/valid.csv\", header = None, index =None)\n",
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10, 25), dtype=float32, numpy=\n",
       " array([[ 1.1596175 ,  0.5965822 , -0.360898  ,  0.16170253,  0.6836721 ,\n",
       "         -0.8577868 ,  1.        ,  0.        ,  1.        ,  1.        ,\n",
       "          0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          1.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  1.        ],\n",
       "        [ 1.224466  ,  0.19681813, -1.4779869 , -0.879606  ,  0.18353444,\n",
       "          2.1232939 ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "          1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  1.        ],\n",
       "        [-1.7369449 , -2.2017663 ,  1.8732799 ,  2.2443194 , -2.2546365 ,\n",
       "          0.79836917,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "          0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          1.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 1.073153  ,  0.99634624, -1.105624  ,  1.203011  ,  0.62115484,\n",
       "          1.295216  ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "          1.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-2.2773483 , -2.2017663 ,  2.245643  , -0.879606  ,  0.49612045,\n",
       "         -0.8577868 ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "          0.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "          1.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ,  1.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-1.6720965 , -1.4022381 ,  1.8732799 ,  2.2443194 ,  0.5586377 ,\n",
       "          1.6264471 ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "          0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "          1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  1.        ,  0.        ],\n",
       "        [ 1.2460821 ,  0.19681813, -0.733261  ,  0.16170253,  0.30856884,\n",
       "          1.1296003 ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "          1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          1.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-1.4559351 , -1.4022381 ,  2.245643  , -0.879606  , -3.3174288 ,\n",
       "          1.1296003 ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "          0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "          1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-1.6504804 , -1.8020022 ,  1.128554  ,  2.2443194 ,  0.43360326,\n",
       "          0.46713796,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "          0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 1.1271933 ,  0.99634624, -1.4779869 , -0.879606  , -0.06653437,\n",
       "         -1.0234023 ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "          1.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "          1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       " array([[ 1.        , -0.27495602],\n",
       "        [ 1.        , -0.2764765 ],\n",
       "        [ 0.        , -0.09162629],\n",
       "        [ 0.        ,  5.654443  ],\n",
       "        [ 0.        , -0.33714336],\n",
       "        [ 0.        , -0.04695284],\n",
       "        [ 0.        , -0.5110337 ],\n",
       "        [ 1.        , -0.24979477],\n",
       "        [ 0.        , -0.29397187],\n",
       "        [ 0.        , -0.41313833]], dtype=float32)>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ihdp_fn(data):\n",
    "    data = tf.strings.to_number(tf.strings.split(data, sep=','))\n",
    "    t, y, y_cf = data[0:1], data[1:2], data[2:3]\n",
    "    mu_0, mu_1, x = data[3:4], data[4:5], data[5:30]\n",
    "    x_bin = x[..., x_num_dim:]  # binary inputs\n",
    "    x_num = x[..., 0:x_num_dim]  # continuous inputs\n",
    "    return x,tf.concat([t,y],-1)\n",
    "    \n",
    "def input_fn_csv(path,name, batch_size=64, shuffle_size=0):\n",
    "    all_files = findfile(path,name)\n",
    "    ds = tf.data.TextLineDataset(\n",
    "        all_files,\n",
    "        compression_type= None,\n",
    "        num_parallel_reads=int(args.num_parallel_reads),\n",
    "        buffer_size=64*1024*1024# 可选参数，多线程并行读多个文件\n",
    "    ).repeat(args.reps)\n",
    "    if shuffle_size > 0:\n",
    "        ds = ds.shuffle(shuffle_size)\n",
    "    ds = ds.map(ihdp_fn).batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "loss_dict = {'huber': tf.keras.losses.Huber(delta=50),\n",
    "             'bce' : tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "             'mae' : tf.keras.losses.MeanAbsoluteError(),\n",
    "             'mse' : tf.keras.losses.MeanSquaredError(),\n",
    "             'msle' : tf.keras.losses.MeanSquaredLogarithmicError(),\n",
    "             'logcosh' : tf.keras.losses.LogCosh(reduction=\"auto\", name=\"log_cosh\"),\n",
    "            }\n",
    "\n",
    "train_dataset = input_fn_csv(\"./datasets/IHDP/csv_create\",'train')\n",
    "valid_dataset = input_fn_csv(\"./datasets/IHDP/csv_create\",'valid')\n",
    "\n",
    "for data in input_fn_csv(\"./datasets/IHDP/csv_create\",'train',10):\n",
    "    break\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'dense_35/kernel:0', 'dense_35/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'dense_35/kernel:0', 'dense_35/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "934/934 [==============================] - 5s 4ms/step - loss: 58.4754\n",
      "Epoch 2/10\n",
      "934/934 [==============================] - 4s 5ms/step - loss: 58.0324\n",
      "Epoch 3/10\n",
      "934/934 [==============================] - 4s 4ms/step - loss: 57.8874\n",
      "Epoch 4/10\n",
      "934/934 [==============================] - 4s 5ms/step - loss: 57.7924\n",
      "Epoch 5/10\n",
      "934/934 [==============================] - 5s 5ms/step - loss: 57.7210\n",
      "Epoch 6/10\n",
      "934/934 [==============================] - 4s 5ms/step - loss: 57.6630\n",
      "Epoch 7/10\n",
      "934/934 [==============================] - 5s 5ms/step - loss: 57.6131\n",
      "Epoch 8/10\n",
      "934/934 [==============================] - 5s 5ms/step - loss: 57.5689\n",
      "Epoch 9/10\n",
      "934/934 [==============================] - 5s 6ms/step - loss: 57.5291\n",
      "Epoch 10/10\n",
      "934/934 [==============================] - 6s 6ms/step - loss: 57.4926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x140144be0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class tarnet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(tarnet, self).__init__()\n",
    "        ########################################\n",
    "        # networks\n",
    "        self.activation = 'elu'\n",
    "        # CEVAE Model (decoder)\n",
    "        self.share_bottom = tfk.Sequential(\n",
    "            [\n",
    "                tfkl.InputLayer([x_bin_dim+x_num_dim]),\n",
    "                tfkl.Dense(200,activation = self.activation),\n",
    "                tfkl.Dense(200,activation = self.activation),\n",
    "                tfkl.Dense(200,activation = self.activation),\n",
    "            ])\n",
    "        self.tower_t0 = tfk.Sequential(\n",
    "            [\n",
    "                tfkl.InputLayer([200]),\n",
    "                tfkl.Dense(100,activation = self.activation),\n",
    "                tfkl.Dense(100,activation = self.activation),\n",
    "                tfkl.Dense(1,activation = None),\n",
    "            ])\n",
    "\n",
    "        self.tower_t1 = tfk.Sequential(\n",
    "            [\n",
    "                tfkl.InputLayer([200]),\n",
    "                tfkl.Dense(100,activation = self.activation),\n",
    "                tfkl.Dense(100,activation = self.activation),\n",
    "                tfkl.Dense(1,activation = None),\n",
    "            ])\n",
    "    def call(self, data, training=False, serving=False):\n",
    "        # Dataset_inp\n",
    "        hidden_bottom = self.share_bottom(data)\n",
    "        y_t0 = self.tower_t0(hidden_bottom)\n",
    "        y_t1 = self.tower_t0(hidden_bottom)\n",
    "    \n",
    "        output = tf.concat([y_t0,y_t1],-1)\n",
    "        return output\n",
    "\n",
    "def tarnet_loss(data,pred):\n",
    "    # get preds\n",
    "    y_t0,y_t1 = pred[...,0],pred[...,1]\n",
    "    # read labels\n",
    "    t_real,y_real = data[...,0], data[...,1]\n",
    "    # calculate loss\n",
    "    loss = tf.math.square(y_t0-y_real) * (1-t_real) + tf.math.square(y_t1-y_real) * (t_real)\n",
    "    loss_mean = tfkb.sum(loss)\n",
    "\n",
    "    return loss_mean\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "def build_model():\n",
    "    model = tarnet()\n",
    "    sgd_lr = 1e-5\n",
    "    momentum = 0.9\n",
    "    model.compile(\n",
    "        optimizer=SGD(\n",
    "            lr=sgd_lr, momentum=momentum, nesterov=True),\n",
    "        loss = tarnet_loss\n",
    "        )\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"fit_logs/\", histogram_freq=1)\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    # validation_data = valid_dataset, \n",
    "    callbacks=[tensorboard_callback],\n",
    "    epochs = 10,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
